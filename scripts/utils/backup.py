#!/usr/bin/env python3
"""
ë°ì´í„° ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
- SQLite ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
- ë¡œê·¸ íŒŒì¼ ì•„ì¹´ì´ë¸Œ
- ì„¤ì • íŒŒì¼ ë°±ì—…
- ìë™ ì••ì¶• ë° ë‚ ì§œë³„ ê´€ë¦¬
"""

import os
import shutil
import sqlite3
import zipfile
from datetime import datetime
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BackupManager:
def __init__(self, backup_dir='backups'):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
def backup_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"""
        try:
            source_db = Path('data/trading.db')
            if not source_db.exists():
                logger.warning("âš ï¸ trading.db íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
            backup_db = self.backup_dir / f'trading_db_{self.timestamp}.db'
            
            # SQLite ë°±ì—… (VACUUMìœ¼ë¡œ ìµœì í™”)
            source_conn = sqlite3.connect(source_db)
            backup_conn = sqlite3.connect(backup_db)
            source_conn.backup(backup_conn)
            source_conn.close()
            backup_conn.close()
            
            logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ: {backup_db}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
def backup_logs(self):
        """ë¡œê·¸ íŒŒì¼ ë°±ì—… ë° ì•„ì¹´ì´ë¸Œ"""
        try:
            logs_dir = Path('logs')
            if not logs_dir.exists():
                logger.warning("âš ï¸ logs ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
            backup_logs_zip = self.backup_dir / f'logs_{self.timestamp}.zip'
            
            with zipfile.ZipFile(backup_logs_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for log_file in logs_dir.glob('*.log'):
                    zipf.write(log_file, log_file.name)
                    
            logger.info(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ë°±ì—… ì™„ë£Œ: {backup_logs_zip}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¡œê·¸ íŒŒì¼ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
def backup_config(self):
        """ì„¤ì • íŒŒì¼ ë°±ì—…"""
        try:
            config_files = [
                'config.yaml',
                '.env.example',
                'requirements.txt'
            ]
            
            backup_config_zip = self.backup_dir / f'config_{self.timestamp}.zip'
            
            with zipfile.ZipFile(backup_config_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for config_file in config_files:
                    file_path = Path(config_file)
                    if file_path.exists():
                        zipf.write(file_path, file_path.name)
                        
            logger.info(f"âš™ï¸ ì„¤ì • íŒŒì¼ ë°±ì—… ì™„ë£Œ: {backup_config_zip}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì„¤ì • íŒŒì¼ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
def backup_historical_data(self):
        """ê³¼ê±° ë°ì´í„° ë°±ì—…"""
        try:
            historical_dir = Path('data/historical')
            if not historical_dir.exists() or not any(historical_dir.iterdir()):
                logger.warning("âš ï¸ ê³¼ê±° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
            backup_historical_zip = self.backup_dir / f'historical_{self.timestamp}.zip'
            
            with zipfile.ZipFile(backup_historical_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for data_file in historical_dir.rglob('*'):
                    if data_file.is_file():
                        # ìƒëŒ€ ê²½ë¡œë¡œ ì €ì¥
                        arcname = data_file.relative_to(historical_dir)
                        zipf.write(data_file, arcname)
                        
            logger.info(f"ğŸ“Š ê³¼ê±° ë°ì´í„° ë°±ì—… ì™„ë£Œ: {backup_historical_zip}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ê³¼ê±° ë°ì´í„° ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
def cleanup_old_backups(self, keep_days=30):
        """ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬"""
        try:
            current_time = datetime.now()
            deleted_count = 0
            
            for backup_file in self.backup_dir.glob('*'):
                if backup_file.is_file():
                    file_time = datetime.fromtimestamp(backup_file.stat().st_mtime)
                    days_old = (current_time - file_time).days
                    
                    if days_old > keep_days:
                        backup_file.unlink()
                        deleted_count += 1
                        logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {backup_file.name}")
            
            if deleted_count > 0:
                logger.info(f"ğŸ§¹ {deleted_count}ê°œì˜ ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
            else:
                logger.info("âœ… ì •ë¦¬í•  ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì—†ìŒ")
                
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
def create_full_backup(self):
        """ì „ì²´ ë°±ì—… ì‹¤í–‰"""
        logger.info(f"ğŸš€ ì „ì²´ ë°±ì—… ì‹œì‘ - {self.timestamp}")
        
        results = []
        results.append(self.backup_database())
        results.append(self.backup_logs())
        results.append(self.backup_config())
        results.append(self.backup_historical_data())
        
        success_count = sum(results)
        total_count = len(results)
        
        logger.info(f"ğŸ“‹ ë°±ì—… ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
        
        # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
        self.cleanup_old_backups()
        
        return success_count == total_count

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë°ì´í„° ë°±ì—… ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--db-only', action='store_true', help='ë°ì´í„°ë² ì´ìŠ¤ë§Œ ë°±ì—…')
    parser.add_argument('--logs-only', action='store_true', help='ë¡œê·¸ íŒŒì¼ë§Œ ë°±ì—…')
    parser.add_argument('--config-only', action='store_true', help='ì„¤ì • íŒŒì¼ë§Œ ë°±ì—…')
    parser.add_argument('--cleanup', action='store_true', help='ì˜¤ë˜ëœ ë°±ì—…ë§Œ ì •ë¦¬')
    parser.add_argument('--keep-days', type=int, default=30, help='ë°±ì—… ë³´ê´€ ì¼ìˆ˜ (ê¸°ë³¸: 30ì¼)')
    
    args = parser.parse_args()
    
    backup_manager = BackupManager()
    
    if args.cleanup:
        backup_manager.cleanup_old_backups(args.keep_days)
    elif args.db_only:
        backup_manager.backup_database()
    elif args.logs_only:
        backup_manager.backup_logs()
    elif args.config_only:
        backup_manager.backup_config()
    else:
        backup_manager.create_full_backup()

if __name__ == "__main__":
    main() 