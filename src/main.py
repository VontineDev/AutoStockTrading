#!/usr/bin/env python3
"""
TA-Lib ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ë©”ì¸ ì§„ì…ì 

pykrx + TA-Lib ê¸°ë°˜ì˜ 100ë§Œì› ê·œëª¨ ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime, timedelta
import yaml
from dotenv import load_dotenv
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì • (print() ëŒ€ì‹  ì‚¬ìš©)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
env_path = PROJECT_ROOT / '.env'
if env_path.exists():
    load_dotenv(env_path)
    logger.info(f"í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ: {env_path}")
else:
    logger.warning(f"í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ì—†ìŒ: {env_path}")

def setup_logging(config: dict):
    """ë¡œê¹… ì„¤ì •"""
    log_config = config.get('logging', {})
    log_level = getattr(logging, log_config.get('level', 'INFO'))
    log_format = log_config.get('format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = PROJECT_ROOT / 'logs'
    log_dir.mkdir(exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    handlers = [
        logging.StreamHandler(sys.stdout)
    ]
    
    if log_config.get('file_logging', {}).get('enabled', True):
        log_file = log_dir / 'main.log'
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    logging.basicConfig(
        level=log_level,
        format=log_format,
        handlers=handlers,
        force=True
    )
    
    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('plotly').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)

def load_config() -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = PROJECT_ROOT / 'config.yaml'
    
    try:
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
    except Exception as e:
        logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
    return {
        'project': {
            'name': 'TA-Lib ìŠ¤ìœ™ íŠ¸ë ˆì´ë”©',
            'version': '1.0.0'
        },
        'logging': {
            'level': 'INFO'
        }
    }

def setup_environment():
    """í™˜ê²½ ì„¤ì •"""
    try:
        from dotenv import load_dotenv
        env_path = PROJECT_ROOT / '.env'
        if env_path.exists():
            load_dotenv(env_path)
            logger.info(f"í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ: {env_path}")
        else:
            logger.warning("í™˜ê²½ë³€ìˆ˜ íŒŒì¼(.env)ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    except ImportError:
        logger.warning("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

def check_dependencies():
    """í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸"""
    required_packages = [
        ('talib', 'TA-Lib'),
        ('pandas', 'pandas'),
        ('numpy', 'numpy'),
        ('pykrx', 'pykrx'),
        ('streamlit', 'streamlit'),
        ('plotly', 'plotly'),
        ('sqlite3', 'sqlite3 (ë‚´ì¥)')
    ]
    
    missing_packages = []
    
    for package, display_name in required_packages:
        try:
            if package == 'sqlite3':
                import sqlite3
            else:
                __import__(package)
            logger.info(f"âœ… {display_name}")
        except ImportError:
            missing_packages.append(display_name)
            logger.error(f"âŒ {display_name} - ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    
    if missing_packages:
        logger.error(f"ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
        logger.info("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        logger.info("pip install -r requirements.txt")
        return False
    
    logger.info("âœ… ëª¨ë“  í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    return True

def parse_date(date_str: str) -> str:
    """ë‚ ì§œ ë¬¸ìì—´ì„ YYYYMMDD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str:
        return None
    
    # ì´ë¯¸ YYYYMMDD í˜•ì‹ì¸ ê²½ìš°
    if len(date_str) == 8 and date_str.isdigit():
        return date_str
    
    # YYYY-MM-DD í˜•ì‹ì¸ ê²½ìš°
    try:
        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        return date_obj.strftime('%Y%m%d')
    except ValueError:
        raise ValueError(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date_str}. YYYY-MM-DD ë˜ëŠ” YYYYMMDD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

def calculate_date_range(args) -> tuple:
    """ì¸ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘/ì¢…ë£Œ ë‚ ì§œ ê³„ì‚°"""
    end_date = datetime.now()
    
    # ì¢…ë£Œ ë‚ ì§œ ì„¤ì •
    if hasattr(args, 'end_date') and args.end_date:
        end_date_str = parse_date(args.end_date)
        end_date = datetime.strptime(end_date_str, '%Y%m%d')
    
    # ì‹œì‘ ë‚ ì§œ ê³„ì‚° ìš°ì„ ìˆœìœ„: start_date > days > period
    if hasattr(args, 'start_date') and args.start_date:
        # ì§ì ‘ ì‹œì‘ ë‚ ì§œ ì§€ì •
        start_date_str = parse_date(args.start_date)
        start_date = datetime.strptime(start_date_str, '%Y%m%d')
    elif hasattr(args, 'days') and args.days:
        # í˜„ì¬ë¶€í„° Nì¼ ì „
        start_date = end_date - timedelta(days=args.days)
    else:
        # ê¸°ë³¸ ê¸°ê°„ ì„¤ì •
        period = getattr(args, 'period', '1y')
        period_days = {
            '1w': 7,
            '1m': 30,
            '3m': 90,
            '6m': 180,
            '1y': 365,  # ê¸°ë³¸ê°’
            '2y': 730
        }
        days = period_days.get(period, 365)
        start_date = end_date - timedelta(days=days)
    
    return start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')

def run_data_update(args):
    """ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
    try:
        from scripts.data_update import StockDataUpdater
        
        updater = StockDataUpdater()
        
        # API ì‚¬ìš©ëŸ‰ í˜„í™©ë§Œ í‘œì‹œ
        if args.api_status:
            status = updater.get_api_usage_status()
            logger.info("\n=== API ì‚¬ìš©ëŸ‰ í˜„í™© ===")
            for key, value in status.items():
                logger.info(f"{key}: {value}")
            return
        
        # ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©ë§Œ í‘œì‹œ
        if hasattr(args, 'summary') and args.summary:
            summary = updater.get_data_summary()
            logger.info("\n=== ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ===")
            logger.info(f"ì¢…ëª© ìˆ˜: {summary.get('symbols_count', 0):,}ê°œ")
            logger.info(f"ë°ì´í„° ê¸°ê°„: {summary.get('date_range', ('N/A', 'N/A'))[0]} ~ {summary.get('date_range', ('N/A', 'N/A'))[1]}")
            logger.info(f"ì´ ë°ì´í„°: {summary.get('total_records', 0):,}ê±´")
            return
        
        # ì „ë‚  ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
        if hasattr(args, 'yesterday_only') and args.yesterday_only:
            logger.info("=== ì „ë‚  ë°ì´í„° ì—…ë°ì´íŠ¸ ëª¨ë“œ ===")
            
            if args.top_kospi and args.top_kospi > 0:
                # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª©
                results = updater.update_yesterday_data(use_kospi_top=True, top_limit=args.top_kospi)
            elif args.symbols:
                # ì§€ì •ëœ ì¢…ëª©ë“¤
                results = updater.update_yesterday_data(symbols=args.symbols)
            else:
                # ê¸°ì¡´ ë“±ë¡ëœ ëª¨ë“  ì¢…ëª©
                results = updater.update_yesterday_data()
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            logger.info(f"\nì „ë‚ ({results['date']}) ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ:")
            logger.info(f"- ì„±ê³µ: {results['success_count']}/{results['total_symbols']} ì¢…ëª©")
            logger.info(f"- ì‹ ê·œ ë°ì´í„°: {results['new_data_count']}ê±´")
            logger.info(f"- ì¤‘ë³µ ê±´ë„ˆëœ€: {results['duplicate_count']}ê±´")
            
            if results['failed_symbols']:
                logger.info(f"- ì‹¤íŒ¨ ì¢…ëª©: {', '.join(results['failed_symbols'])}")
            
            return
        
        # ì¢…ëª© ì„ íƒ
        if args.top_kospi and args.top_kospi > 0:
            # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª©
            symbols = updater.get_kospi_top_symbols(args.top_kospi)
            logger.info(f"ì½”ìŠ¤í”¼ ìƒìœ„ {len(symbols)}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘")
        elif args.symbols:
            symbols = args.symbols
            logger.info(f"ì§€ì • ì¢…ëª© {len(symbols)}ê°œ ë°ì´í„° ìˆ˜ì§‘")
        else:
            # ê¸°ë³¸ê°’: ì½”ìŠ¤í”¼ ìƒìœ„ 30ê°œ
            symbols = updater.get_kospi_top_symbols(30)
            logger.info("ê¸°ë³¸ê°’: ì½”ìŠ¤í”¼ ìƒìœ„ 30ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘")
        
        # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        try:
            start_date, end_date = calculate_date_range(args)
            
            # ê¸°ê°„ ê³„ì‚° ë° í‘œì‹œ
            start_dt = datetime.strptime(start_date, '%Y%m%d')
            end_dt = datetime.strptime(end_date, '%Y%m%d')
            days_diff = (end_dt - start_dt).days
            
            logger.info(f"\n=== ë°ì´í„° ìˆ˜ì§‘ ë²”ìœ„ ===")
            logger.info(f"ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date} ({days_diff}ì¼)")
            logger.info(f"ëŒ€ìƒ ì¢…ëª©: {len(symbols)}ê°œ")
            
            # ë‚ ì§œ ì„¤ì • ë°©ì‹ í‘œì‹œ
            if hasattr(args, 'start_date') and args.start_date:
                logger.info(f"ë‚ ì§œ ì„¤ì •: ì§ì ‘ ì§€ì • ({args.start_date} ~ {getattr(args, 'end_date', 'ì˜¤ëŠ˜')})")
            elif hasattr(args, 'days') and args.days:
                logger.info(f"ë‚ ì§œ ì„¤ì •: ìµœê·¼ {args.days}ì¼")
            else:
                period = getattr(args, 'period', '1y')
                period_names = {'1w': '1ì£¼', '1m': '1ê°œì›”', '3m': '3ê°œì›”', '6m': '6ê°œì›”', '1y': '1ë…„', '2y': '2ë…„'}
                logger.info(f"ë‚ ì§œ ì„¤ì •: ê¸°ë³¸ ê¸°ê°„ ({period_names.get(period, period)})")
                
        except ValueError as e:
            logger.error(f"ë‚ ì§œ ì„¤ì • ì˜¤ë¥˜: {e}")
            return
        
        # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ì•ˆë‚´
        if hasattr(args, 'yesterday_only') and not args.yesterday_only:
            if len(symbols) > 10 and days_diff > 30:
                estimated_time = len(symbols) * 2  # ì¢…ëª©ë‹¹ ì•½ 2ë¶„ ì˜ˆìƒ
                logger.info(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {estimated_time}ë¶„")
                logger.info("ì „ë‚  ë°ì´í„°ë§Œ í•„ìš”í•œ ê²½ìš° --yesterday-only ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš” (Ultra-Fast, 4-5ì´ˆ ì™„ë£Œ)")
        
        # ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰ (ë³‘ë ¬/ìˆœì°¨ ì²˜ë¦¬ ì„ íƒ)
        if hasattr(updater, 'update_multiple_symbols'):
            # ë³‘ë ¬ ì²˜ë¦¬ ì—¬ë¶€ ê²°ì •
            if getattr(args, 'parallel', False):
                workers = getattr(args, 'workers', 5)
                logger.info(f"\nğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™” (ì›Œì»¤: {workers}ê°œ)")
                if hasattr(updater, 'update_multiple_symbols_parallel'):
                    results = updater.update_multiple_symbols_parallel(
                        symbols, start_date, end_date, 
                        force_update=getattr(args, 'force', False),
                        max_workers=workers
                    )
                else:
                    logger.error("âŒ ë³‘ë ¬ ì²˜ë¦¬ê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìˆœì°¨ ì²˜ë¦¬ë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
                    results = updater.update_multiple_symbols(symbols, start_date, end_date, 
                                                            force_update=getattr(args, 'force', False))
            else:
                # ìˆœì°¨ ì²˜ë¦¬ (ê¸°ë³¸)
                logger.info(f"\nğŸŒ ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ (ê¸°ë³¸)")
                results = updater.update_multiple_symbols(symbols, start_date, end_date, 
                                                        force_update=getattr(args, 'force', False))
            
            # ê²°ê³¼ ìš”ì•½
            success_count = sum(1 for success in results.values() if success)
            logger.info(f"\n=== ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ===")
            logger.info(f"ì„±ê³µ: {success_count}/{len(symbols)} ì¢…ëª©")
            
            # ì‹¤íŒ¨í•œ ì¢…ëª© í‘œì‹œ
            failed_symbols = [symbol for symbol, success in results.items() if not success]
            if failed_symbols:
                logger.info(f"ì‹¤íŒ¨: {', '.join(failed_symbols)}")
        else:
            # ê¸°ì¡´ ë°©ì‹: ê°œë³„ ì¢…ëª© ì—…ë°ì´íŠ¸
            for i, symbol in enumerate(symbols, 1):
                logger.info(f"[{i}/{len(symbols)}] {symbol} ì²˜ë¦¬ ì¤‘...")
                try:
                    updater.update_symbol(symbol, start_date, end_date, 
                                        force_update=getattr(args, 'force', False))
                    logger.info(f"  âœ… ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"  âŒ ì‹¤íŒ¨: {e}")
        
        # API ì‚¬ìš©ëŸ‰ í˜„í™©
        status = updater.get_api_usage_status()
        logger.info(f"\nAPI ì‚¬ìš©ëŸ‰: {status.get('total_calls', 0)}íšŒ í˜¸ì¶œ")
        
    except Exception as e:
        logger.error(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        logger.info(f"ì˜¤ë¥˜: {e}")

def run_backtest(args):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)"""
    try:
        from src.strategies.macd_strategy import MACDStrategy
        from src.strategies.rsi_strategy import RSIStrategy
        from src.strategies.bollinger_band_strategy import BollingerBandStrategy
        from src.strategies.moving_average_strategy import MovingAverageStrategy
        from src.trading.backtest import BacktestEngine, BacktestConfig
        import pandas as pd
        import sqlite3
        import time
        from datetime import datetime, timedelta
        from pathlib import Path
        import json
        
        logger.info("ğŸš€ ë°±í…ŒìŠ¤íŒ… ì‹œì‘...")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
        db_path = PROJECT_ROOT / 'data' / 'trading.db'
        if not db_path.exists():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
            logger.info("python src/main.py update-data --top-kospi 962 --period 2y --parallel")
            return
        
        # ì¢…ëª© ì„ íƒ ë¡œì§
        symbols = []
        if args.all_kospi:
            logger.info("ğŸ“Š ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª© ë°±í…ŒìŠ¤íŒ… ëª¨ë“œ")
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT DISTINCT symbol FROM stock_data ORDER BY symbol")
                symbols = [row[0] for row in cursor.fetchall()]
            logger.info(f"ì½”ìŠ¤í”¼ ì „ì²´ {len(symbols)}ê°œ ì¢…ëª© ëŒ€ìƒ")
        elif args.top_kospi:
            logger.info(f"ğŸ“Š ì½”ìŠ¤í”¼ ìƒìœ„ {args.top_kospi}ê°œ ì¢…ëª© ë°±í…ŒìŠ¤íŒ…")
            # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª© ê°€ì ¸ì˜¤ê¸° (pykrx ì‚¬ìš©)
            try:
                from scripts.data_update import StockDataUpdater
                updater = StockDataUpdater()
                symbols = updater.get_kospi_top_symbols(args.top_kospi)
            except:
                # ëŒ€ì²´ ë°©ë²•: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ê°€ ë§ì€ ì¢…ëª© ìˆœìœ¼ë¡œ
                with sqlite3.connect(db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT symbol, COUNT(*) as count 
                        FROM stock_data 
                        GROUP BY symbol 
                        ORDER BY count DESC 
                        LIMIT ?
                    """, (args.top_kospi,))
                    symbols = [row[0] for row in cursor.fetchall()]
        elif args.symbols:
            symbols = args.symbols
            logger.info(f"ğŸ“Š ì§€ì • ì¢…ëª© {len(symbols)}ê°œ ë°±í…ŒìŠ¤íŒ…")
        else:
            symbols = ['005930']  # ê¸°ë³¸: ì‚¼ì„±ì „ì
            logger.info("ğŸ“Š ê¸°ë³¸ê°’: ì‚¼ì„±ì „ì ë°±í…ŒìŠ¤íŒ…")
        
        # ë°±í…ŒìŠ¤íŒ… ê¸°ê°„ ì„¤ì •
        end_date = datetime.now()
        if hasattr(args, 'end_date') and args.end_date:
            end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
        
        start_date = end_date - timedelta(days=args.days)
        if hasattr(args, 'start_date') and args.start_date:
            start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
        
        logger.info(f"ğŸ“… ë°±í…ŒìŠ¤íŒ… ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ({args.days}ì¼)")
        
        # ë°ì´í„° ë¡œë“œ
        logger.info("ğŸ“š ë°ì´í„° ë¡œë”© ì¤‘...")
        data = {}
        failed_symbols = []
        
        with sqlite3.connect(db_path) as conn:
            for symbol in symbols:
                query = """
                SELECT date, open, high, low, close, volume
                FROM stock_data 
                WHERE symbol = ? AND DATE(date) >= ? AND DATE(date) <= ?
                ORDER BY date
                """
                
                try:
                    df = pd.read_sql_query(query, conn, params=(
                        symbol, 
                        start_date.strftime('%Y-%m-%d'),
                        end_date.strftime('%Y-%m-%d')
                    ))
                    
                    if not df.empty and len(df) >= 20:  # ìµœì†Œ 20ì¼ ë°ì´í„°ë¡œ ì™„í™”
                        # ë‚ ì§œ í˜•ì‹ í†µì¼ (ì‹œê°„ ì •ë³´ ì œê±°)
                        df['date'] = pd.to_datetime(df['date'].str.split(' ').str[0], format='mixed', errors='coerce')  # ë‚ ì§œë§Œ ì¶”ì¶œ
                        df.set_index('date', inplace=True)
                        data[symbol] = df
                        logger.info(f"âœ… {symbol}: {len(df)}ê±´ ë¡œë“œ")
                    else:
                        failed_symbols.append(symbol)
                        logger.info(f"âŒ {symbol}: ë°ì´í„° ë¶€ì¡± ({len(df) if not df.empty else 0}ê±´)")
                        
                except Exception as e:
                    failed_symbols.append(symbol)
                    logger.error(f"âŒ {symbol}: ë¡œë“œ ì‹¤íŒ¨ ({e})")
                    continue
        
        if not data:
            logger.error("âŒ ë°±í…ŒìŠ¤íŒ…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if failed_symbols:
            logger.warning(f"âš ï¸  ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì œì™¸ëœ ì¢…ëª©: {len(failed_symbols)}ê°œ")
        
        logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ì¢…ëª©")
        
        # ì „ëµ ì„¤ì •
        strategy_name = getattr(args, 'strategy', 'macd').lower()
        strategies = {
            'macd': MACDStrategy,
            'rsi': RSIStrategy,
            'bollinger': BollingerBandStrategy,
            'ma': MovingAverageStrategy
        }
        
        strategies_to_test = []
        if strategy_name == 'all':
            strategies_to_test = list(strategies.items())
            logger.info("ğŸ¯ ëª¨ë“  ì „ëµ ë°±í…ŒìŠ¤íŒ…")
        else:
            if strategy_name not in strategies:
                logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì „ëµ: {strategy_name}")
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì „ëµ: {', '.join(strategies.keys())}, all")
                return
            strategies_to_test = [(strategy_name, strategies[strategy_name])]
            logger.info(f"ğŸ¯ ì „ëµ: {strategy_name}")
        
        # ğŸ¤– ì¢…ëª© ìˆ˜ì— ë”°ë¥¸ ìµœì  ì—”ì§„ ìë™ ì„ íƒ
        num_symbols = len(data)
        force_parallel = getattr(args, 'parallel', False)
        force_optimized = getattr(args, 'optimized', False)
        
        # ì—”ì§„ ì„ íƒ ë¡œì§
        if force_optimized:
            engine_type = 'optimized'
            logger.info(f"ğŸ¯ ì‚¬ìš©ì ì§€ì •: OptimizedBacktestEngine (ìºì‹± + ë³‘ë ¬ + ë°°ì¹˜)")
        elif force_parallel:
            engine_type = 'parallel'
            logger.info(f"ğŸ¯ ì‚¬ìš©ì ì§€ì •: ParallelBacktestEngine (ë³‘ë ¬ ì²˜ë¦¬)")
        elif num_symbols >= 100:
            engine_type = 'optimized'
            logger.info(f"ğŸš€ ìë™ ì„ íƒ: OptimizedBacktestEngine (ëŒ€ê·œëª¨ {num_symbols}ê°œ ì¢…ëª©)")
            logger.info("   â””â”€ ì´ìœ : ìºì‹± + ë©”ëª¨ë¦¬ ìµœì í™” + ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœê³  ì„±ëŠ¥")
        elif num_symbols >= 10:
            engine_type = 'parallel'
            logger.info(f"âš¡ ìë™ ì„ íƒ: ParallelBacktestEngine (ì¤‘ê·œëª¨ {num_symbols}ê°œ ì¢…ëª©)")
            logger.info("   â””â”€ ì´ìœ : ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœì  ì„±ëŠ¥/ì•ˆì •ì„± ê· í˜•")
        else:
            engine_type = 'sequential'
            logger.info(f"ğŸŒ ìë™ ì„ íƒ: BacktestEngine (ì†Œê·œëª¨ {num_symbols}ê°œ ì¢…ëª©)")
            logger.info("   â””â”€ ì´ìœ : ìˆœì°¨ ì²˜ë¦¬ë¡œ ë””ë²„ê¹… ë° ìƒì„¸ ë¶„ì„ ìµœì í™”")
        
        # ì„±ëŠ¥ ì˜ˆì¸¡ ì •ë³´ ì¶œë ¥
        if num_symbols > 1:
            if engine_type == 'optimized':
                estimated_time = max(30, num_symbols * 0.15)  # ëŒ€ê·œëª¨ì—ì„œ ìºì‹± íš¨ê³¼
                logger.info(f"   â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time:.0f}ì´ˆ (ìºì‹œ íˆíŠ¸ ì‹œ 90% ë‹¨ì¶•)")
            elif engine_type == 'parallel':
                estimated_time = max(10, num_symbols * 0.25)  # ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼
                logger.info(f"   â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time:.0f}ì´ˆ (ìˆœì°¨ ëŒ€ë¹„ {min(args.workers, 8)}ë°° ë¹ ë¦„)")
            else:
                estimated_time = num_symbols * 2  # ìˆœì°¨ ì²˜ë¦¬
                logger.info(f"   â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time:.0f}ì´ˆ (ìƒì„¸ ë¶„ì„ í¬í•¨)")
        
        # ì„ íƒëœ ì—”ì§„ìœ¼ë¡œ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
        all_results = {}
        total_start_time = time.time()
        
        if engine_type == 'optimized':
            # OptimizedBacktestEngine ì‚¬ìš©
            logger.info(f"\nğŸš€ ìµœì í™” ì—”ì§„ ì‹œì‘ (ì›Œì»¤: {args.workers}ê°œ, ìºì‹œ: í™œì„±í™”)")
            logger.info("   ğŸ“Š ë‚´ë¶€ì ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ì™€ ìºì‹±ì„ í†µí•© ìš´ì˜í•©ë‹ˆë‹¤")
            
            from src.trading.optimized_backtest import OptimizedBacktestEngine, OptimizedBacktestConfig
            
            optimized_config = OptimizedBacktestConfig(
                max_workers=args.workers,
                chunk_size=args.chunk_size,
                enable_cache=True,
                cache_max_age_hours=24,
                batch_size=args.chunk_size,
                max_memory_usage_mb=1024,
                initial_capital=1000000
            )
            
            optimized_engine = OptimizedBacktestEngine(optimized_config)
            
            for strategy_name, strategy_class in strategies_to_test:
                logger.info(f"\nğŸ”„ {strategy_name} ì „ëµ ìµœì í™” ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰...")
                strategy_start_time = time.time()
                
                optimized_results = optimized_engine.run_optimized_backtest(
                    strategy_class=strategy_class,
                    symbols=list(data.keys()),
                    strategy_params={},
                    days=args.days
                )
                
                strategy_elapsed = time.time() - strategy_start_time
                logger.info(f"âœ… {strategy_name} ì™„ë£Œ: {strategy_elapsed:.1f}ì´ˆ")
                
                # ìµœì í™” ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
                opt_stats = optimized_results.get('optimization_stats', {})
                cache_efficiency = opt_stats.get('cache_efficiency', 0)
                memory_efficiency = opt_stats.get('memory_efficiency', 0)
                if cache_efficiency > 0 or memory_efficiency > 0:
                    logger.info(f"   â””â”€ ìºì‹œ íš¨ìœ¨ì„±: {cache_efficiency:.1%}, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {memory_efficiency:.1%}")
                
                all_results[strategy_name] = optimized_results
                
        elif engine_type == 'parallel':
            # ParallelBacktestEngine ì‚¬ìš©
            logger.info(f"\nâš¡ ë³‘ë ¬ ì—”ì§„ ì‹œì‘ (ì›Œì»¤: {args.workers}ê°œ, ì²­í¬: {args.chunk_size}ê°œ)")
            
            from src.trading.parallel_backtest import ParallelBacktestEngine, ParallelBacktestConfig
            
            parallel_config = ParallelBacktestConfig(
                max_workers=args.workers,
                chunk_size=args.chunk_size,
                timeout=600  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            parallel_engine = ParallelBacktestEngine(parallel_config)
            
            for strategy_name, strategy_class in strategies_to_test:
                logger.info(f"\nğŸ”„ {strategy_name} ì „ëµ ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰...")
                strategy_start_time = time.time()
                
                parallel_results = parallel_engine.run_parallel_backtest(
                    strategy_class=strategy_class,
                    symbols_data=data,
                    strategy_params={},
                    backtest_config={'initial_capital': 1000000}
                )
                
                strategy_elapsed = time.time() - strategy_start_time
                success_count = parallel_results['performance_stats']['successful_backtests']
                success_rate = success_count / num_symbols * 100
                processing_speed = num_symbols / strategy_elapsed
                
                logger.info(f"âœ… {strategy_name} ì™„ë£Œ: {strategy_elapsed:.1f}ì´ˆ")
                logger.info(f"   â””â”€ ì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{num_symbols}) | ì²˜ë¦¬ ì†ë„: {processing_speed:.1f} ì¢…ëª©/ì´ˆ")
                
                all_results[strategy_name] = parallel_results
                
        else:  # sequential
            # BacktestEngine ì‚¬ìš© (ìˆœì°¨ ì²˜ë¦¬)
            logger.info("\nğŸŒ ìˆœì°¨ ì—”ì§„ ì‹œì‘ (ë””ë²„ê¹… ìµœì í™”)")
            
            config = BacktestConfig(initial_capital=1000000)
            engine = BacktestEngine(config)
            
            for strategy_name, strategy_class in strategies_to_test:
                logger.info(f"\nğŸ”„ {strategy_name} ì „ëµ ìˆœì°¨ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰...")
                strategy_start_time = time.time()
                
                strategy = strategy_class()
                results = engine.run_backtest(strategy, data, 
                                            start_date.strftime('%Y-%m-%d'), 
                                            end_date.strftime('%Y-%m-%d'))
                
                strategy_elapsed = time.time() - strategy_start_time
                total_trades = results.get('total_trades', 0)
                total_return = results.get('total_return', 0)
                
                logger.info(f"âœ… {strategy_name} ì™„ë£Œ: {strategy_elapsed:.1f}ì´ˆ")
                logger.info(f"   â””â”€ ì´ ê±°ë˜: {total_trades}íšŒ, ìˆ˜ìµë¥ : {total_return:.2%}")
                
                all_results[strategy_name] = {'results': {f'portfolio': results}}
        
        # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        total_elapsed = time.time() - total_start_time
        logger.info(f"\nğŸ ì „ì²´ ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ: {total_elapsed:.1f}ì´ˆ")
        
        # ì„±ëŠ¥ í‰ê°€ ì¶œë ¥
        if num_symbols > 1:
            overall_speed = num_symbols * len(strategies_to_test) / total_elapsed
            logger.info(f"   ğŸ“ˆ ì „ì²´ ì²˜ë¦¬ ì†ë„: {overall_speed:.1f} ì¢…ëª©Ã—ì „ëµ/ì´ˆ")
            
            if engine_type == 'parallel':
                efficiency = min(args.workers, num_symbols) / (total_elapsed / (num_symbols * len(strategies_to_test) * 2))
                logger.info(f"   âš¡ ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„±: {efficiency:.1f}ë°° (ìˆœì°¨ ì²˜ë¦¬ ëŒ€ë¹„)")
            elif engine_type == 'optimized':
                logger.info(f"   ğŸš€ ìµœì í™” ì—”ì§„ ì„ íƒìœ¼ë¡œ ëŒ€ê·œëª¨ ì²˜ë¦¬ ì„±ê³µ")
        
        # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ìš”ì•½")
        logger.info("="*60)
        
        for strategy_name, strategy_results in all_results.items():
            logger.info(f"\nğŸ¯ [{strategy_name.upper()} ì „ëµ]")
            
            if 'results' in strategy_results:
                results_data = strategy_results['results']
                
                # ì„±ê³¼ í†µê³„ ê³„ì‚°
                if results_data:
                    # ì²« ë²ˆì§¸ ì¢…ëª©ì˜ ê²°ê³¼ êµ¬ì¡° í™•ì¸
                    sample_result = next(iter(results_data.values()))
                    
                    if isinstance(sample_result, dict):
                        total_returns = [r.get('total_return', 0) for r in results_data.values() if isinstance(r, dict)]
                        sharpe_ratios = [r.get('sharpe_ratio', 0) for r in results_data.values() if isinstance(r, dict)]
                        max_drawdowns = [r.get('max_drawdown', 0) for r in results_data.values() if isinstance(r, dict)]
                        win_rates = [r.get('win_rate', 0) for r in results_data.values() if isinstance(r, dict)]
                        total_trades = [r.get('total_trades', 0) for r in results_data.values() if isinstance(r, dict)]
                        
                        if total_returns:
                            logger.info(f"  í‰ê·  ìˆ˜ìµë¥ : {sum(total_returns)/len(total_returns):.2%}")
                            logger.info(f"  í‰ê·  ìƒ¤í”„ ë¹„ìœ¨: {sum(sharpe_ratios)/len(sharpe_ratios):.3f}")
                            logger.info(f"  í‰ê·  ìµœëŒ€ ë‚™í­: {sum(max_drawdowns)/len(max_drawdowns):.2%}")
                            logger.info(f"  í‰ê·  ìŠ¹ë¥ : {sum(win_rates)/len(win_rates):.2%}")
                            logger.info(f"  ì´ ê±°ë˜ ìˆ˜: {sum(total_trades):,}íšŒ")
                            logger.info(f"  ì²˜ë¦¬ ì¢…ëª© ìˆ˜: {len(results_data)}ê°œ")
        
        # ê²°ê³¼ ì €ì¥
        if getattr(args, 'save_results', False):
            output_dir = Path(args.output_dir)
            output_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # JSON ì €ì¥
            json_file = output_dir / f'backtest_results_{timestamp}.json'
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {json_file}")
        
        logger.info("\nâœ… ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ!")
        
    except Exception as e:
        import traceback
        logger.error(f"âŒ ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        logger.error(f"ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")

def run_streamlit():
    """Streamlit ì›¹ ì•± ì‹¤í–‰"""
    try:
        import streamlit.web.cli as stcli
        import sys
        
        # Streamlit ì•± íŒŒì¼ ê²½ë¡œ
        app_file = PROJECT_ROOT / 'streamlit_app' / 'app.py'
        
        if not app_file.exists():
            logger.error(f"Streamlit ì•± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {app_file}")
            logger.info("streamlit_app/app.pyë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return
        
        logger.info("Streamlit ì›¹ ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        logger.info("ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì„ ì—´ì–´ì£¼ì„¸ìš”.")
        
        # Streamlit ì‹¤í–‰
        sys.argv = ["streamlit", "run", str(app_file)]
        stcli.main()
        
    except Exception as e:
        logger.error(f"Streamlit ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        logger.info("Streamlitì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'pip install streamlit'ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

def run_optimization(args):
    """ë§¤ê°œë³€ìˆ˜ ìµœì í™” ì‹¤í–‰"""
    try:
        from src.ui.optimization import ParameterOptimizer
        from src.strategies.macd_strategy import MACDStrategy
        import pandas as pd
        import sqlite3
        
        logger.info("ë§¤ê°œë³€ìˆ˜ ìµœì í™” ì‹œì‘...")
        
        # ë°ì´í„° ë¡œë“œ (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼)
        db_path = PROJECT_ROOT / 'data' / 'trading.db'
        if not db_path.exists():
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
            return
        
        symbols = args.symbols or ['005930']
        data = {}
        
        with sqlite3.connect(db_path) as conn:
            for symbol in symbols:
                query = """
                SELECT date, open, high, low, close, volume
                FROM stock_data 
                WHERE symbol = ?
                ORDER BY date
                """
                df = pd.read_sql_query(query, conn, params=(symbol,))
                
                if not df.empty:
                    df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')
                    df.set_index('date', inplace=True)
                    data[symbol] = df
        
        if not data:
            logger.error("ìµœì í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë§¤ê°œë³€ìˆ˜ ë²”ìœ„ ì„¤ì •
        param_ranges = {
            'fast_period': [8, 10, 12, 14, 16],
            'slow_period': [21, 24, 26, 28, 30],
            'signal_period': [7, 8, 9, 10, 11]
        }
        
        # ìµœì í™” ì‹¤í–‰
        optimizer = ParameterOptimizer()
        results = optimizer.run_grid_search(
            strategy_class=MACDStrategy,
            data=data,
            param_ranges=param_ranges,
            metric='sharpe_ratio',
            max_combinations=50
        )
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n=== ìµœì í™” ê²°ê³¼ ===")
        logger.info(f"ìµœì  ë§¤ê°œë³€ìˆ˜: {results['best_parameters']}")
        logger.info(f"ìµœê³  ì„±ê³¼: {results['best_score']:.4f}")
        logger.info(f"í…ŒìŠ¤íŠ¸ ì¡°í•©: {results['total_combinations']}ê°œ")
        
    except Exception as e:
        logger.error(f"ìµœì í™” ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    
    # í™˜ê²½ ì„¤ì •
    setup_environment()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(config)
    
    logger.info(f"=== {config['project']['name']} v{config['project']['version']} ===")
    
    # ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(
        description='TA-Lib ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python src/main.py check-deps           # íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
  
  # ë°ì´í„° ì—…ë°ì´íŠ¸ (ê¸°ë³¸: 1ë…„ ë°ì´í„°)
  python src/main.py update-data          # ì½”ìŠ¤í”¼ ìƒìœ„ 30ì¢…ëª© 1ë…„ ë°ì´í„° ì—…ë°ì´íŠ¸
  python src/main.py update-data --top-kospi 50  # ì½”ìŠ¤í”¼ ìƒìœ„ 50ì¢…ëª© 1ë…„ ë°ì´í„°
  python src/main.py update-data --symbols 005930 000660  # íŠ¹ì • ì¢…ëª© 1ë…„ ë°ì´í„°
  
  # ë‚ ì§œ ë²”ìœ„ ì§€ì •
  python src/main.py update-data --days 180    # ìµœê·¼ 180ì¼ ë°ì´í„°
  python src/main.py update-data --period 6m   # ìµœê·¼ 6ê°œì›” ë°ì´í„°
  python src/main.py update-data --period 2y   # ìµœê·¼ 2ë…„ ë°ì´í„°
  python src/main.py update-data --start-date 2024-01-01 --end-date 2024-06-30  # íŠ¹ì • ê¸°ê°„
  python src/main.py update-data --start-date 20240101  # 2024ë…„ 1ì›” 1ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
  
  # ë¹ ë¥¸ ì—…ë°ì´íŠ¸ (Ultra-Fast)
  python src/main.py update-data --yesterday-only  # ì „ë‚  ë°ì´í„°ë§Œ (4-5ì´ˆ ì™„ë£Œ)
  python src/main.py update-data -y --top-kospi 30  # ì½”ìŠ¤í”¼ ìƒìœ„ 30ì¢…ëª© ì „ë‚  ë°ì´í„°
  
  # ìƒíƒœ í™•ì¸
  python src/main.py update-data --summary     # ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© í™•ì¸
  python src/main.py update-data --api-status  # API ì‚¬ìš©ëŸ‰ í™•ì¸
  
  # ë°±í…ŒìŠ¤íŒ… (ê¸°ë³¸)
  python src/main.py backtest                  # ì‚¼ì„±ì „ì 180ì¼ ë°±í…ŒìŠ¤íŒ… (MACD ì „ëµ)
  python src/main.py backtest --symbols 005930 000660  # íŠ¹ì • ì¢…ëª© ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --strategy rsi   # RSI ì „ëµìœ¼ë¡œ ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --start-date 2024-01-01 --end-date 2024-06-30  # ê¸°ê°„ ì§€ì •
  
  # ëŒ€ê·œëª¨ ë°±í…ŒìŠ¤íŒ… (ë³‘ë ¬ ì²˜ë¦¬)
  python src/main.py backtest --top-kospi 10 --parallel  # ì½”ìŠ¤í”¼ ìƒìœ„ 10ì¢…ëª© ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --all-kospi --parallel --workers 8  # ì½”ìŠ¤í”¼ ì „ì²´ ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --strategy all --top-kospi 50 --parallel  # ëª¨ë“  ì „ëµ í…ŒìŠ¤íŠ¸
  
  # ê²°ê³¼ ì €ì¥
  python src/main.py backtest --all-kospi --parallel --save-results  # ê²°ê³¼ JSON ì €ì¥
  
  # ë§¤ê°œë³€ìˆ˜ ìµœì í™” ë° ì›¹ ì¸í„°í˜ì´ìŠ¤
  python src/main.py optimize                 # ë§¤ê°œë³€ìˆ˜ ìµœì í™”
  python src/main.py web                      # ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # íŒ¨í‚¤ì§€ í™•ì¸ ëª…ë ¹ì–´
    subparsers.add_parser('check-deps', help='í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸')
    
    # ë°ì´í„° ì—…ë°ì´íŠ¸ ëª…ë ¹ì–´
    update_parser = subparsers.add_parser('update-data', help='ì£¼ì‹ ë°ì´í„° ì—…ë°ì´íŠ¸')
    update_parser.add_argument('--symbols', nargs='+', help='ì—…ë°ì´íŠ¸í•  ì¢…ëª© ì½”ë“œë“¤')
    update_parser.add_argument('--top-kospi', type=int, default=30, dest='top_kospi', help='ì½”ìŠ¤í”¼ ìƒìœ„ Nê°œ ì¢…ëª© (ê¸°ë³¸: 30)')
    update_parser.add_argument('--force', action='store_true', help='ê°•ì œ ì—…ë°ì´íŠ¸')
    update_parser.add_argument('--summary', action='store_true', help='ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ë³´ê¸°')
    update_parser.add_argument('--api-status', action='store_true', dest='api_status', help='API ì‚¬ìš©ëŸ‰ í˜„í™© ë³´ê¸°')
    update_parser.add_argument('--yesterday-only', '-y', action='store_true', dest='yesterday_only', help='ì „ë‚  ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸ (íš¨ìœ¨ì )')
    
    # ë‚ ì§œ ë²”ìœ„ ì˜µì…˜ ì¶”ê°€
    date_group = update_parser.add_argument_group('ë‚ ì§œ ë²”ìœ„ ì„¤ì •')
    date_group.add_argument('--days', type=int, help='í˜„ì¬ë¶€í„° Nì¼ ì „ê¹Œì§€ ë°ì´í„° ìˆ˜ì§‘ (ì˜ˆ: 180)')
    date_group.add_argument('--start-date', help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYYMMDD í˜•ì‹)')
    date_group.add_argument('--end-date', help='ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYYMMDD í˜•ì‹, ê¸°ë³¸: ì˜¤ëŠ˜)')
    date_group.add_argument('--period', choices=['1w', '1m', '3m', '6m', '1y', '2y'], default='1y', 
                           help='ê¸°ë³¸ ìˆ˜ì§‘ ê¸°ê°„ (ê¸°ë³¸: 1y=1ë…„)')
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ ì¶”ê°€
    parallel_group = update_parser.add_argument_group('ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •')
    parallel_group.add_argument('--parallel', '-p', action='store_true', help='ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ (ë¹ ë¥¸ ì†ë„)')
    parallel_group.add_argument('--workers', type=int, default=5, help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 5)')
    
    # ë°±í…ŒìŠ¤íŒ… ëª…ë ¹ì–´
    backtest_parser = subparsers.add_parser('backtest', help='ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰')
    backtest_parser.add_argument('--symbols', nargs='+', help='ë°±í…ŒìŠ¤íŒ…í•  ì¢…ëª© ì½”ë“œë“¤')
    backtest_parser.add_argument('--top-kospi', type=int, help='ì½”ìŠ¤í”¼ ìƒìœ„ Nê°œ ì¢…ëª© ë°±í…ŒìŠ¤íŒ…')
    backtest_parser.add_argument('--all-kospi', action='store_true', help='ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª© ë°±í…ŒìŠ¤íŒ… (962ê°œ)')
    backtest_parser.add_argument('--start-date', dest='start_date', help='ë°±í…ŒìŠ¤íŒ… ì‹œì‘ë‚ ì§œ (YYYY-MM-DD)')
    backtest_parser.add_argument('--end-date', dest='end_date', help='ë°±í…ŒìŠ¤íŒ… ì¢…ë£Œë‚ ì§œ (YYYY-MM-DD)')
    backtest_parser.add_argument('--days', type=int, default=180, help='ë°±í…ŒìŠ¤íŒ… ê¸°ê°„ (ì¼ìˆ˜, ê¸°ë³¸: 180ì¼)')
    backtest_parser.add_argument('--strategy', choices=['macd', 'rsi', 'bollinger', 'ma', 'all'], 
                                default='macd', help='ì‚¬ìš©í•  ì „ëµ (ê¸°ë³¸: macd, all: ëª¨ë“  ì „ëµ)')
    
    # ë°±í…ŒìŠ¤íŒ… ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜
    backtest_parallel_group = backtest_parser.add_argument_group('ì—”ì§„ ì„ íƒ ë° ì„±ëŠ¥ ì„¤ì •')
    backtest_parallel_group.add_argument('--parallel', '-p', action='store_true', help='ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ ê°•ì œ ì‚¬ìš© (ì¤‘ê·œëª¨ ìµœì )')
    backtest_parallel_group.add_argument('--optimized', '-o', action='store_true', help='ìµœì í™” ì—”ì§„ ê°•ì œ ì‚¬ìš© (ëŒ€ê·œëª¨ ìµœì , ìºì‹±)')
    backtest_parallel_group.add_argument('--workers', type=int, default=4, help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 4)')
    backtest_parallel_group.add_argument('--chunk-size', type=int, default=20, help='ì²­í¬ë‹¹ ì¢…ëª© ìˆ˜ (ê¸°ë³¸: 20)')
    
    # ìë™ ì—”ì§„ ì„ íƒ ì•ˆë‚´
    engine_help = backtest_parser.add_argument_group('ìë™ ì—”ì§„ ì„ íƒ (ì˜µì…˜ ë¯¸ì§€ì • ì‹œ)')
    engine_help.description = """
    ğŸ¤– ì¢…ëª© ìˆ˜ì— ë”°ë¥¸ ìë™ ì—”ì§„ ì„ íƒ:
    â€¢ 1-9ê°œ ì¢…ëª©: BacktestEngine (ìˆœì°¨ ì²˜ë¦¬, ë””ë²„ê¹… ìµœì )
    â€¢ 10-99ê°œ ì¢…ëª©: ParallelBacktestEngine (ë³‘ë ¬ ì²˜ë¦¬, ì„±ëŠ¥/ì•ˆì •ì„± ê· í˜•)  
    â€¢ 100ê°œ+ ì¢…ëª©: OptimizedBacktestEngine (ìºì‹±+ë³‘ë ¬+ë°°ì¹˜, ìµœê³  ì„±ëŠ¥)
    """
    
    # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì €ì¥ ì˜µì…˜
    backtest_output_group = backtest_parser.add_argument_group('ê²°ê³¼ ì €ì¥')
    backtest_output_group.add_argument('--save-results', action='store_true', help='ê²°ê³¼ë¥¼ CSV/JSONìœ¼ë¡œ ì €ì¥')
    backtest_output_group.add_argument('--output-dir', default='backtest_results', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: backtest_results)')
    
    # ìµœì í™” ëª…ë ¹ì–´
    optimize_parser = subparsers.add_parser('optimize', help='ë§¤ê°œë³€ìˆ˜ ìµœì í™”')
    optimize_parser.add_argument('--symbols', nargs='+', help='ìµœì í™”í•  ì¢…ëª© ì½”ë“œë“¤')
    
    # ì›¹ ì¸í„°í˜ì´ìŠ¤ ëª…ë ¹ì–´
    subparsers.add_parser('web', help='Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰')
    
    # ì¸ì íŒŒì‹±
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # ëª…ë ¹ì–´ ì‹¤í–‰
    try:
        if args.command == 'check-deps':
            if check_dependencies():
                logger.info("\nì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                sys.exit(1)
                
        elif args.command == 'update-data':
            run_data_update(args)
            
        elif args.command == 'backtest':
            run_backtest(args)
            
        elif args.command == 'optimize':
            run_optimization(args)
            
        elif args.command == 'web':
            run_streamlit()
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 