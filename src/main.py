#!/usr/bin/env python3
"""
TA-Lib ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ë©”ì¸ ì§„ì…ì 

pykrx + TA-Lib ê¸°ë°˜ì˜ 100ë§Œì› ê·œëª¨ ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime, timedelta
import yaml
from dotenv import load_dotenv
import pandas as pd
import json
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì • (print() ëŒ€ì‹  ì‚¬ìš©)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
env_path = PROJECT_ROOT / '.env'
if env_path.exists():
    load_dotenv(env_path)
    logger.info(f"í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ: {env_path}")
else:
    logger.warning(f"í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ì—†ìŒ: {env_path}")

def setup_logging(config: dict):
    """ë¡œê¹… ì„¤ì •"""
    log_config = config.get('logging', {})
    log_level = getattr(logging, log_config.get('level', 'INFO'))
    log_format = log_config.get('format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = PROJECT_ROOT / 'logs'
    log_dir.mkdir(exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    handlers = [
        logging.StreamHandler(sys.stdout)
    ]
    
    if log_config.get('file_logging', {}).get('enabled', True):
        log_file = log_dir / 'main.log'
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    logging.basicConfig(
        level=log_level,
        format=log_format,
        handlers=handlers,
        force=True
    )
    
    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('plotly').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)

def load_config() -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = PROJECT_ROOT / 'config.yaml'
    
    try:
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
    except Exception as e:
        logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
    return {
        'project': {
            'name': 'TA-Lib ìŠ¤ìœ™ íŠ¸ë ˆì´ë”©',
            'version': '1.0.0'
        },
        'logging': {
            'level': 'INFO'
        }
    }

def setup_environment():
    """í™˜ê²½ ì„¤ì •"""
    try:
        from dotenv import load_dotenv
        env_path = PROJECT_ROOT / '.env'
        if env_path.exists():
            load_dotenv(env_path)
            logger.info(f"í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ: {env_path}")
        else:
            logger.warning("í™˜ê²½ë³€ìˆ˜ íŒŒì¼(.env)ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    except ImportError:
        logger.warning("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

def check_dependencies():
    """í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸"""
    required_packages = [
        ('talib', 'TA-Lib'),
        ('pandas', 'pandas'),
        ('numpy', 'numpy'),
        ('pykrx', 'pykrx'),
        ('streamlit', 'streamlit'),
        ('plotly', 'plotly'),
        ('sqlite3', 'sqlite3 (ë‚´ì¥)')
    ]
    
    missing_packages = []
    
    for package, display_name in required_packages:
        try:
            if package == 'sqlite3':
                import sqlite3
            else:
                __import__(package)
            logger.info(f"âœ… {display_name}")
        except ImportError:
            missing_packages.append(display_name)
            logger.error(f"âŒ {display_name} - ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    
    if missing_packages:
        logger.error(f"ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
        logger.info("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        logger.info("pip install -r requirements.txt")
        return False
    
    logger.info("âœ… ëª¨ë“  í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    return True

def parse_date(date_str: str) -> str:
    """ë‚ ì§œ ë¬¸ìì—´ì„ YYYYMMDD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str:
        return None
    
    # ì´ë¯¸ YYYYMMDD í˜•ì‹ì¸ ê²½ìš°
    if len(date_str) == 8 and date_str.isdigit():
        return date_str
    
    # YYYY-MM-DD í˜•ì‹ì¸ ê²½ìš°
    try:
        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        return date_obj.strftime('%Y%m%d')
    except ValueError:
        raise ValueError(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date_str}. YYYY-MM-DD ë˜ëŠ” YYYYMMDD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

def calculate_date_range(args) -> tuple:
    """ì¸ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘/ì¢…ë£Œ ë‚ ì§œ ê³„ì‚°"""
    end_date = datetime.now()
    
    # ì¢…ë£Œ ë‚ ì§œ ì„¤ì •
    if hasattr(args, 'end_date') and args.end_date:
        end_date_str = parse_date(args.end_date)
        end_date = datetime.strptime(end_date_str, '%Y%m%d')
    
    # ì‹œì‘ ë‚ ì§œ ê³„ì‚° ìš°ì„ ìˆœìœ„: start_date > days > period
    if hasattr(args, 'start_date') and args.start_date:
        # ì§ì ‘ ì‹œì‘ ë‚ ì§œ ì§€ì •
        start_date_str = parse_date(args.start_date)
        start_date = datetime.strptime(start_date_str, '%Y%m%d')
    elif hasattr(args, 'days') and args.days:
        # í˜„ì¬ë¶€í„° Nì¼ ì „
        start_date = end_date - timedelta(days=args.days)
    else:
        # ê¸°ë³¸ ê¸°ê°„ ì„¤ì •
        period = getattr(args, 'period', '1y')
        period_days = {
            '1w': 7,
            '1m': 30,
            '3m': 90,
            '6m': 180,
            '1y': 365,  # ê¸°ë³¸ê°’
            '2y': 730
        }
        days = period_days.get(period, 365)
        start_date = end_date - timedelta(days=days)
    
    return start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')

def run_data_update(args):
    """ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
    try:
        from scripts.data_update import StockDataUpdater
        
        updater = StockDataUpdater()
        
        # API ì‚¬ìš©ëŸ‰ í˜„í™©ë§Œ í‘œì‹œ
        if args.api_status:
            status = updater.get_api_usage_status()
            logger.info("\n=== API ì‚¬ìš©ëŸ‰ í˜„í™© ===")
            for key, value in status.items():
                logger.info(f"{key}: {value}")
            return
        
        # ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©ë§Œ í‘œì‹œ
        if hasattr(args, 'summary') and args.summary:
            # ë°±í…ŒìŠ¤íŒ… ë¶„ì„ í¬í•¨ ì—¬ë¶€ í™•ì¸
            include_backtest = getattr(args, 'backtest_analysis', False)
            
            if include_backtest:
                # ì¢…í•© ìƒíƒœ ë¶„ì„
                comprehensive_status = updater.get_comprehensive_status(include_backtest_analysis=True)
                
                # ê¸°ë³¸ ìš”ì•½
                basic = comprehensive_status.get('basic_summary', {})
                logger.info("\n=== ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ í˜„í™© ===")
                logger.info(f"ì¢…ëª© ìˆ˜: {basic.get('symbols_count', 0):,}ê°œ")
                logger.info(f"ë°ì´í„° ê¸°ê°„: {basic.get('date_range', ('N/A', 'N/A'))[0]} ~ {basic.get('date_range', ('N/A', 'N/A'))[1]}")
                logger.info(f"ì´ ë°ì´í„°: {basic.get('total_records', 0):,}ê±´")
                logger.info(f"DB ê²½ë¡œ: {basic.get('db_path', 'N/A')}")
                
                # ë°±í…ŒìŠ¤íŒ… ë¶„ì„
                backtest = comprehensive_status.get('backtest_analysis', {})
                if backtest:
                    logger.info(f"\n=== ğŸš€ ë°±í…ŒìŠ¤íŒ… ì í•©ì„± ë¶„ì„ ===")
                    logger.info(f"ë¶„ì„ ê¸°ê°„: {backtest.get('analysis_period', 'N/A')}")
                    logger.info(f"ìµœì†Œ ë°ì´í„° ìš”êµ¬: {backtest.get('min_data_days', 0)}ì¼")
                    logger.info(f"ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥ ì¢…ëª©: {backtest.get('valid_symbols_count', 0):,}ê°œ ({backtest.get('valid_percentage', 0)}%)")
                    
                    # ìƒìœ„ ì¢…ëª© í‘œì‹œ
                    top_symbols = backtest.get('top_symbols', [])
                    if top_symbols:
                        logger.info(f"\nğŸ“ˆ ë°ì´í„°ê°€ ê°€ì¥ ì¶©ì‹¤í•œ ìƒìœ„ {len(top_symbols)}ê°œ ì¢…ëª©:")
                        for i, symbol_info in enumerate(top_symbols[:10], 1):
                            symbol = symbol_info['symbol']
                            days = symbol_info['days']
                            start_date = symbol_info['start_date']
                            end_date = symbol_info['end_date']
                            logger.info(f"  {i:2d}. {symbol}: {days}ì¼ ({start_date} ~ {end_date})")
                        
                        if len(top_symbols) > 10:
                            logger.info(f"     ... ì™¸ {len(top_symbols) - 10}ê°œ ì¢…ëª©")
                    
                    # í…ŒìŠ¤íŠ¸ ì¶”ì²œ ì¢…ëª©
                    test_symbols = backtest.get('test_symbols_string', '')
                    if test_symbols:
                        logger.info(f"\nğŸ¯ ë°±í…ŒìŠ¤íŒ… í…ŒìŠ¤íŠ¸ ì¶”ì²œ ì¢…ëª© (ìƒìœ„ 10ê°œ):")
                        logger.info(f"   {test_symbols}")
                
                # API ìƒíƒœ
                api_status = comprehensive_status.get('api_status', {})
                if api_status:
                    logger.info(f"\n=== ğŸ”Œ API ì‚¬ìš© í˜„í™© ===")
                    logger.info(f"ì„¸ì…˜ í˜¸ì¶œ: {api_status.get('api_calls', 0)}íšŒ")
                    logger.info(f"ì„¸ì…˜ ì‹œê°„: {api_status.get('session_duration', 'N/A')}")
                    logger.info(f"ë¶„ë‹¹ í˜¸ì¶œ: {api_status.get('calls_per_minute', 0):.1f}íšŒ")
                    
            else:
                # ê¸°ì¡´ ê°„ë‹¨í•œ ìš”ì•½
                summary = updater.get_data_summary()
                logger.info("\n=== ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ===")
                logger.info(f"ì¢…ëª© ìˆ˜: {summary.get('symbols_count', 0):,}ê°œ")
                logger.info(f"ë°ì´í„° ê¸°ê°„: {summary.get('date_range', ('N/A', 'N/A'))[0]} ~ {summary.get('date_range', ('N/A', 'N/A'))[1]}")
                logger.info(f"ì´ ë°ì´í„°: {summary.get('total_records', 0):,}ê±´")
            return
        
        # ì „ë‚  ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
        if hasattr(args, 'yesterday_only') and args.yesterday_only:
            logger.info("=== ì „ë‚  ë°ì´í„° ì—…ë°ì´íŠ¸ ëª¨ë“œ ===")
            
            if hasattr(args, 'all_kospi') and args.all_kospi:
                # ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª©
                all_symbols = updater.get_kospi_symbols()
                results = updater.update_yesterday_data(symbols=all_symbols)
                logger.info(f"ì½”ìŠ¤í”¼ ì „ì²´ {len(all_symbols)}ê°œ ì¢…ëª© ì „ë‚  ë°ì´í„° ì—…ë°ì´íŠ¸")
            elif args.top_kospi and args.top_kospi > 0:
                # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª©
                results = updater.update_yesterday_data(use_kospi_top=True, top_limit=args.top_kospi)
            elif args.symbols:
                # ì§€ì •ëœ ì¢…ëª©ë“¤
                results = updater.update_yesterday_data(symbols=args.symbols)
            else:
                # ê¸°ì¡´ ë“±ë¡ëœ ëª¨ë“  ì¢…ëª©
                results = updater.update_yesterday_data()
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            logger.info(f"\nì „ë‚ ({results['date']}) ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ:")
            logger.info(f"- ì„±ê³µ: {results['success_count']}/{results['total_symbols']} ì¢…ëª©")
            logger.info(f"- ì‹ ê·œ ë°ì´í„°: {results['new_data_count']}ê±´")
            logger.info(f"- ì¤‘ë³µ ê±´ë„ˆëœ€: {results['duplicate_count']}ê±´")
            
            if results['failed_symbols']:
                logger.info(f"- ì‹¤íŒ¨ ì¢…ëª©: {', '.join(results['failed_symbols'])}")
            
            return
        
        # ì¢…ëª© ì„ íƒ
        if hasattr(args, 'all_kospi') and args.all_kospi:
            # ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª©
            symbols = updater.get_kospi_symbols()
            logger.info(f"ì½”ìŠ¤í”¼ ì „ì²´ {len(symbols)}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘")
        elif args.top_kospi and args.top_kospi > 0:
            # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª©
            symbols = updater.get_kospi_top_symbols(args.top_kospi)
            logger.info(f"ì½”ìŠ¤í”¼ ìƒìœ„ {len(symbols)}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘")
        elif args.symbols:
            symbols = args.symbols
            logger.info(f"ì§€ì • ì¢…ëª© {len(symbols)}ê°œ ë°ì´í„° ìˆ˜ì§‘")
        else:
            # ê¸°ë³¸ê°’: ì½”ìŠ¤í”¼ ìƒìœ„ 30ê°œ
            symbols = updater.get_kospi_top_symbols(30)
            logger.info("ê¸°ë³¸ê°’: ì½”ìŠ¤í”¼ ìƒìœ„ 30ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘")
        
        # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        try:
            start_date, end_date = calculate_date_range(args)
            
            # ê¸°ê°„ ê³„ì‚° ë° í‘œì‹œ
            start_dt = datetime.strptime(start_date, '%Y%m%d')
            end_dt = datetime.strptime(end_date, '%Y%m%d')
            days_diff = (end_dt - start_dt).days
            
            logger.info(f"\n=== ë°ì´í„° ìˆ˜ì§‘ ë²”ìœ„ ===")
            logger.info(f"ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date} ({days_diff}ì¼)")
            logger.info(f"ëŒ€ìƒ ì¢…ëª©: {len(symbols)}ê°œ")
            
            # ë‚ ì§œ ì„¤ì • ë°©ì‹ í‘œì‹œ
            if hasattr(args, 'start_date') and args.start_date:
                logger.info(f"ë‚ ì§œ ì„¤ì •: ì§ì ‘ ì§€ì • ({args.start_date} ~ {getattr(args, 'end_date', 'ì˜¤ëŠ˜')})")
            elif hasattr(args, 'days') and args.days:
                logger.info(f"ë‚ ì§œ ì„¤ì •: ìµœê·¼ {args.days}ì¼")
            else:
                period = getattr(args, 'period', '1y')
                period_names = {'1w': '1ì£¼', '1m': '1ê°œì›”', '3m': '3ê°œì›”', '6m': '6ê°œì›”', '1y': '1ë…„', '2y': '2ë…„'}
                logger.info(f"ë‚ ì§œ ì„¤ì •: ê¸°ë³¸ ê¸°ê°„ ({period_names.get(period, period)})")
                
        except ValueError as e:
            logger.error(f"ë‚ ì§œ ì„¤ì • ì˜¤ë¥˜: {e}")
            return
        
        # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ì•ˆë‚´
        if hasattr(args, 'yesterday_only') and not args.yesterday_only:
            if len(symbols) > 10 and days_diff > 30:
                estimated_time = len(symbols) * 2  # ì¢…ëª©ë‹¹ ì•½ 2ë¶„ ì˜ˆìƒ
                logger.info(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {estimated_time}ë¶„")
                logger.info("ì „ë‚  ë°ì´í„°ë§Œ í•„ìš”í•œ ê²½ìš° --yesterday-only ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš” (Ultra-Fast, 4-5ì´ˆ ì™„ë£Œ)")
        
        # ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰ (ë³‘ë ¬/ìˆœì°¨ ì²˜ë¦¬ ì„ íƒ)
        if hasattr(updater, 'update_multiple_symbols'):
            # ë³‘ë ¬ ì²˜ë¦¬ ì—¬ë¶€ ê²°ì •
            if getattr(args, 'parallel', False):
                workers = getattr(args, 'workers', 5)
                logger.info(f"\nğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™” (ì›Œì»¤: {workers}ê°œ)")
                if hasattr(updater, 'update_multiple_symbols_parallel'):
                    results = updater.update_multiple_symbols_parallel(
                        symbols, start_date, end_date, 
                        force_update=getattr(args, 'force', False),
                        max_workers=workers
                    )
                else:
                    logger.error("âŒ ë³‘ë ¬ ì²˜ë¦¬ê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìˆœì°¨ ì²˜ë¦¬ë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
                    results = updater.update_multiple_symbols(symbols, start_date, end_date, 
                                                            force_update=getattr(args, 'force', False))
            else:
                # ìˆœì°¨ ì²˜ë¦¬ (ê¸°ë³¸)
                logger.info(f"\nğŸŒ ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ (ê¸°ë³¸)")
                results = updater.update_multiple_symbols(symbols, start_date, end_date, 
                                                        force_update=getattr(args, 'force', False))
            
            # ê²°ê³¼ ìš”ì•½
            success_count = sum(1 for success in results.values() if success)
            logger.info(f"\n=== ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ===")
            logger.info(f"ì„±ê³µ: {success_count}/{len(symbols)} ì¢…ëª©")
            
            # ì‹¤íŒ¨í•œ ì¢…ëª© í‘œì‹œ
            failed_symbols = [symbol for symbol, success in results.items() if not success]
            if failed_symbols:
                logger.info(f"ì‹¤íŒ¨: {', '.join(failed_symbols)}")
        else:
            # ê¸°ì¡´ ë°©ì‹: ê°œë³„ ì¢…ëª© ì—…ë°ì´íŠ¸
            for i, symbol in enumerate(symbols, 1):
                logger.info(f"[{i}/{len(symbols)}] {symbol} ì²˜ë¦¬ ì¤‘...")
                try:
                    updater.update_symbol(symbol, start_date, end_date, 
                                        force_update=getattr(args, 'force', False))
                    logger.info(f"  âœ… ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"  âŒ ì‹¤íŒ¨: {e}")
        
        # API ì‚¬ìš©ëŸ‰ í˜„í™©
        status = updater.get_api_usage_status()
        logger.info(f"\nAPI ì‚¬ìš©ëŸ‰: {status.get('total_calls', 0)}íšŒ í˜¸ì¶œ")
        
    except Exception as e:
        logger.error(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        logger.info(f"ì˜¤ë¥˜: {e}")

def run_backtest(args):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)"""
    try:
        from src.strategies.macd_strategy import MACDStrategy
        from src.strategies.rsi_strategy import RSIStrategy
        from src.strategies.bollinger_band_strategy import BollingerBandStrategy
        from src.strategies.moving_average_strategy import MovingAverageStrategy
        from src.trading.backtest import BacktestEngine, BacktestConfig
        import pandas as pd
        import sqlite3
        import time
        from datetime import datetime, timedelta
        from pathlib import Path
        import json
        
        logger.info("ğŸš€ ë°±í…ŒìŠ¤íŒ… ì‹œì‘...")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
        db_path = PROJECT_ROOT / 'data' / 'trading.db'
        if not db_path.exists():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
            logger.info("python src/main.py update-data --top-kospi 962 --period 2y --parallel")
            return
        
        # ì¢…ëª© ì„ íƒ ë¡œì§
        symbols = []
        if args.all_kospi:
            logger.info("ğŸ“Š ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª© ë°±í…ŒìŠ¤íŒ… ëª¨ë“œ")
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT DISTINCT symbol FROM stock_data ORDER BY symbol")
                symbols = [row[0] for row in cursor.fetchall()]
            logger.info(f"ì½”ìŠ¤í”¼ ì „ì²´ {len(symbols)}ê°œ ì¢…ëª© ëŒ€ìƒ")
        elif args.top_kospi:
            logger.info(f"ğŸ“Š ì½”ìŠ¤í”¼ ìƒìœ„ {args.top_kospi}ê°œ ì¢…ëª© ë°±í…ŒìŠ¤íŒ…")
            # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª© ê°€ì ¸ì˜¤ê¸° (pykrx ì‚¬ìš©)
            try:
                from scripts.data_update import StockDataUpdater
                updater = StockDataUpdater()
                symbols = updater.get_kospi_top_symbols(args.top_kospi)
            except:
                # ëŒ€ì²´ ë°©ë²•: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ê°€ ë§ì€ ì¢…ëª© ìˆœìœ¼ë¡œ
                with sqlite3.connect(db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT symbol, COUNT(*) as count 
                        FROM stock_data 
                        GROUP BY symbol 
                        ORDER BY count DESC 
                        LIMIT ?
                    """, (args.top_kospi,))
                    symbols = [row[0] for row in cursor.fetchall()]
        elif args.symbols:
            symbols = args.symbols
            logger.info(f"ğŸ“Š ì§€ì • ì¢…ëª© {len(symbols)}ê°œ ë°±í…ŒìŠ¤íŒ…")
        else:
            symbols = ['005930']  # ê¸°ë³¸: ì‚¼ì„±ì „ì
            logger.info("ğŸ“Š ê¸°ë³¸ê°’: ì‚¼ì„±ì „ì ë°±í…ŒìŠ¤íŒ…")
        
        # ë°±í…ŒìŠ¤íŒ… ê¸°ê°„ ì„¤ì •
        end_date = datetime.now()
        if hasattr(args, 'end_date') and args.end_date:
            end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
        
        start_date = end_date - timedelta(days=args.days)
        if hasattr(args, 'start_date') and args.start_date:
            start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
        
        logger.info(f"ğŸ“… ë°±í…ŒìŠ¤íŒ… ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ({args.days}ì¼)")
        
        # ë°ì´í„° ë¡œë“œ
        logger.info("ğŸ“š ë°ì´í„° ë¡œë”© ì¤‘...")
        data = {}
        failed_symbols = []
        
        with sqlite3.connect(db_path) as conn:
            for symbol in symbols:
                query = """
                SELECT date, open, high, low, close, volume
                FROM stock_data 
                WHERE symbol = ? AND DATE(date) >= ? AND DATE(date) <= ?
                ORDER BY date
                """
                
                try:
                    df = pd.read_sql_query(query, conn, params=(
                        symbol, 
                        start_date.strftime('%Y-%m-%d'),
                        end_date.strftime('%Y-%m-%d')
                    ))
                    
                    if not df.empty and len(df) >= 20:  # ìµœì†Œ 20ì¼ ë°ì´í„°ë¡œ ì™„í™”
                        # ë‚ ì§œ í˜•ì‹ í†µì¼ (ì‹œê°„ ì •ë³´ ì œê±°)
                        df['date'] = pd.to_datetime(df['date'].str.split(' ').str[0], format='mixed', errors='coerce')  # ë‚ ì§œë§Œ ì¶”ì¶œ
                        df.set_index('date', inplace=True)
                        data[symbol] = df
                        logger.info(f"âœ… {symbol}: {len(df)}ê±´ ë¡œë“œ")
                    else:
                        failed_symbols.append(symbol)
                        logger.info(f"âŒ {symbol}: ë°ì´í„° ë¶€ì¡± ({len(df) if not df.empty else 0}ê±´)")
                        
                except Exception as e:
                    failed_symbols.append(symbol)
                    logger.error(f"âŒ {symbol}: ë¡œë“œ ì‹¤íŒ¨ ({e})")
                    continue
        
        if not data:
            logger.error("âŒ ë°±í…ŒìŠ¤íŒ…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if failed_symbols:
            logger.warning(f"âš ï¸  ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì œì™¸ëœ ì¢…ëª©: {len(failed_symbols)}ê°œ")
        
        logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ì¢…ëª©")
        
        # ì „ëµ ì„¤ì •
        strategy_name = getattr(args, 'strategy', 'macd').lower()
        strategies = {
            'macd': MACDStrategy,
            'rsi': RSIStrategy,
            'bollinger': BollingerBandStrategy,
            'ma': MovingAverageStrategy
        }
        
        strategies_to_test = []
        if strategy_name == 'all':
            strategies_to_test = list(strategies.items())
            logger.info("ğŸ¯ ëª¨ë“  ì „ëµ ë°±í…ŒìŠ¤íŒ…")
        else:
            if strategy_name not in strategies:
                logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì „ëµ: {strategy_name}")
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì „ëµ: {', '.join(strategies.keys())}, all")
                return
            strategies_to_test = [(strategy_name, strategies[strategy_name])]
            logger.info(f"ğŸ¯ ì „ëµ: {strategy_name}")
        
        # ğŸ¤– ì¢…ëª© ìˆ˜ì— ë”°ë¥¸ ìµœì  ì—”ì§„ ìë™ ì„ íƒ
        num_symbols = len(data)
        force_parallel = getattr(args, 'parallel', False)
        force_optimized = getattr(args, 'optimized', False)
        
        # ì—”ì§„ ì„ íƒ ë¡œì§
        if force_optimized:
            engine_type = 'optimized'
            logger.info(f"ğŸ¯ ì‚¬ìš©ì ì§€ì •: OptimizedBacktestEngine (ìºì‹± + ë³‘ë ¬ + ë°°ì¹˜)")
        elif force_parallel:
            engine_type = 'parallel'
            logger.info(f"ğŸ¯ ì‚¬ìš©ì ì§€ì •: ParallelBacktestEngine (ë³‘ë ¬ ì²˜ë¦¬)")
        elif num_symbols >= 100:
            engine_type = 'optimized'
            logger.info(f"ğŸš€ ìë™ ì„ íƒ: OptimizedBacktestEngine (ëŒ€ê·œëª¨ {num_symbols}ê°œ ì¢…ëª©)")
            logger.info("   â””â”€ ì´ìœ : ìºì‹± + ë©”ëª¨ë¦¬ ìµœì í™” + ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœê³  ì„±ëŠ¥")
        elif num_symbols >= 10:
            engine_type = 'parallel'
            logger.info(f"âš¡ ìë™ ì„ íƒ: ParallelBacktestEngine (ì¤‘ê·œëª¨ {num_symbols}ê°œ ì¢…ëª©)")
            logger.info("   â””â”€ ì´ìœ : ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœì  ì„±ëŠ¥/ì•ˆì •ì„± ê· í˜•")
        else:
            engine_type = 'sequential'
            logger.info(f"ğŸŒ ìë™ ì„ íƒ: BacktestEngine (ì†Œê·œëª¨ {num_symbols}ê°œ ì¢…ëª©)")
            logger.info("   â””â”€ ì´ìœ : ìˆœì°¨ ì²˜ë¦¬ë¡œ ë””ë²„ê¹… ë° ìƒì„¸ ë¶„ì„ ìµœì í™”")
        
        # ì„±ëŠ¥ ì˜ˆì¸¡ ì •ë³´ ì¶œë ¥
        if num_symbols > 1:
            if engine_type == 'optimized':
                estimated_time = max(30, num_symbols * 0.15)  # ëŒ€ê·œëª¨ì—ì„œ ìºì‹± íš¨ê³¼
                logger.info(f"   â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time:.0f}ì´ˆ (ìºì‹œ íˆíŠ¸ ì‹œ 90% ë‹¨ì¶•)")
            elif engine_type == 'parallel':
                estimated_time = max(10, num_symbols * 0.25)  # ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼
                logger.info(f"   â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time:.0f}ì´ˆ (ìˆœì°¨ ëŒ€ë¹„ {min(args.workers, 8)}ë°° ë¹ ë¦„)")
            else:
                estimated_time = num_symbols * 2  # ìˆœì°¨ ì²˜ë¦¬
                logger.info(f"   â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time:.0f}ì´ˆ (ìƒì„¸ ë¶„ì„ í¬í•¨)")
        
        # ì„ íƒëœ ì—”ì§„ìœ¼ë¡œ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
        all_results = {}
        total_start_time = time.time()
        
        if engine_type == 'optimized':
            # OptimizedBacktestEngine ì‚¬ìš©
            logger.info(f"\nğŸš€ ìµœì í™” ì—”ì§„ ì‹œì‘ (ì›Œì»¤: {args.workers}ê°œ, ìºì‹œ: í™œì„±í™”)")
            logger.info("   ğŸ“Š ë‚´ë¶€ì ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ì™€ ìºì‹±ì„ í†µí•© ìš´ì˜í•©ë‹ˆë‹¤")
            
            from src.trading.optimized_backtest import OptimizedBacktestEngine, OptimizedBacktestConfig
            
            optimized_config = OptimizedBacktestConfig(
                max_workers=args.workers,
                chunk_size=args.chunk_size,
                enable_cache=True,
                cache_max_age_hours=24,
                batch_size=args.chunk_size,
                max_memory_usage_mb=1024,
                initial_capital=1000000
            )
            
            optimized_engine = OptimizedBacktestEngine(optimized_config)
            
            for strategy_name, strategy_class in strategies_to_test:
                logger.info(f"\nğŸ”„ {strategy_name} ì „ëµ ìµœì í™” ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰...")
                strategy_start_time = time.time()
                
                optimized_results = optimized_engine.run_optimized_backtest(
                    strategy_class=strategy_class,
                    symbols=list(data.keys()),
                    strategy_params={},
                    days=args.days
                )
                
                strategy_elapsed = time.time() - strategy_start_time
                logger.info(f"âœ… {strategy_name} ì™„ë£Œ: {strategy_elapsed:.1f}ì´ˆ")
                
                # ìµœì í™” ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
                opt_stats = optimized_results.get('optimization_stats', {})
                cache_efficiency = opt_stats.get('cache_efficiency', 0)
                memory_efficiency = opt_stats.get('memory_efficiency', 0)
                if cache_efficiency > 0 or memory_efficiency > 0:
                    logger.info(f"   â””â”€ ìºì‹œ íš¨ìœ¨ì„±: {cache_efficiency:.1%}, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {memory_efficiency:.1%}")
                
                all_results[strategy_name] = optimized_results
                
        elif engine_type == 'parallel':
            # ParallelBacktestEngine ì‚¬ìš©
            logger.info(f"\nâš¡ ë³‘ë ¬ ì—”ì§„ ì‹œì‘ (ì›Œì»¤: {args.workers}ê°œ, ì²­í¬: {args.chunk_size}ê°œ)")
            
            from src.trading.parallel_backtest import ParallelBacktestEngine, ParallelBacktestConfig
            
            parallel_config = ParallelBacktestConfig(
                max_workers=args.workers,
                chunk_size=args.chunk_size,
                timeout=600  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            parallel_engine = ParallelBacktestEngine(parallel_config)
            
            for strategy_name, strategy_class in strategies_to_test:
                logger.info(f"\nğŸ”„ {strategy_name} ì „ëµ ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰...")
                strategy_start_time = time.time()
                
                parallel_results = parallel_engine.run_parallel_backtest(
                    strategy_class=strategy_class,
                    symbols_data=data,
                    strategy_params={},
                    backtest_config={'initial_capital': 1000000}
                )
                
                strategy_elapsed = time.time() - strategy_start_time
                success_count = parallel_results['performance_stats']['successful_backtests']
                success_rate = success_count / num_symbols * 100
                processing_speed = num_symbols / strategy_elapsed
                
                logger.info(f"âœ… {strategy_name} ì™„ë£Œ: {strategy_elapsed:.1f}ì´ˆ")
                logger.info(f"   â””â”€ ì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{num_symbols}) | ì²˜ë¦¬ ì†ë„: {processing_speed:.1f} ì¢…ëª©/ì´ˆ")
                
                all_results[strategy_name] = parallel_results
                
        else:  # sequential
            # BacktestEngine ì‚¬ìš© (ìˆœì°¨ ì²˜ë¦¬)
            logger.info("\nğŸŒ ìˆœì°¨ ì—”ì§„ ì‹œì‘ (ë””ë²„ê¹… ìµœì í™”)")
            
            config = BacktestConfig(initial_capital=1000000)
            engine = BacktestEngine(config)
            
            for strategy_name, strategy_class in strategies_to_test:
                logger.info(f"\nğŸ”„ {strategy_name} ì „ëµ ìˆœì°¨ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰...")
                strategy_start_time = time.time()
                
                strategy = strategy_class()
                results = engine.run_backtest(strategy, data, 
                                            start_date.strftime('%Y-%m-%d'), 
                                            end_date.strftime('%Y-%m-%d'))
                
                strategy_elapsed = time.time() - strategy_start_time
                total_trades = results.get('total_trades', 0)
                total_return = results.get('total_return', 0)
                
                logger.info(f"âœ… {strategy_name} ì™„ë£Œ: {strategy_elapsed:.1f}ì´ˆ")
                logger.info(f"   â””â”€ ì´ ê±°ë˜: {total_trades}íšŒ, ìˆ˜ìµë¥ : {total_return:.2%}")
                
                all_results[strategy_name] = {'results': {f'portfolio': results}}
        
        # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        total_elapsed = time.time() - total_start_time
        logger.info(f"\nğŸ ì „ì²´ ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ: {total_elapsed:.1f}ì´ˆ")
        
        # ì„±ëŠ¥ í‰ê°€ ì¶œë ¥
        if num_symbols > 1:
            overall_speed = num_symbols * len(strategies_to_test) / total_elapsed
            logger.info(f"   ğŸ“ˆ ì „ì²´ ì²˜ë¦¬ ì†ë„: {overall_speed:.1f} ì¢…ëª©Ã—ì „ëµ/ì´ˆ")
            
            if engine_type == 'parallel':
                efficiency = min(args.workers, num_symbols) / (total_elapsed / (num_symbols * len(strategies_to_test) * 2))
                logger.info(f"   âš¡ ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„±: {efficiency:.1f}ë°° (ìˆœì°¨ ì²˜ë¦¬ ëŒ€ë¹„)")
            elif engine_type == 'optimized':
                logger.info(f"   ğŸš€ ìµœì í™” ì—”ì§„ ì„ íƒìœ¼ë¡œ ëŒ€ê·œëª¨ ì²˜ë¦¬ ì„±ê³µ")
        
        # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ìš”ì•½")
        logger.info("="*60)
        
        for strategy_name, strategy_results in all_results.items():
            logger.info(f"\nğŸ¯ [{strategy_name.upper()} ì „ëµ]")
            
            if 'results' in strategy_results:
                results_data = strategy_results['results']
                
                # ì„±ê³¼ í†µê³„ ê³„ì‚°
                if results_data:
                    # ì²« ë²ˆì§¸ ì¢…ëª©ì˜ ê²°ê³¼ êµ¬ì¡° í™•ì¸
                    sample_result = next(iter(results_data.values()))
                    
                    if isinstance(sample_result, dict):
                        total_returns = [r.get('total_return', 0) for r in results_data.values() if isinstance(r, dict)]
                        sharpe_ratios = [r.get('sharpe_ratio', 0) for r in results_data.values() if isinstance(r, dict)]
                        max_drawdowns = [r.get('max_drawdown', 0) for r in results_data.values() if isinstance(r, dict)]
                        win_rates = [r.get('win_rate', 0) for r in results_data.values() if isinstance(r, dict)]
                        total_trades = [r.get('total_trades', 0) for r in results_data.values() if isinstance(r, dict)]
                        
                        if total_returns:
                            logger.info(f"  í‰ê·  ìˆ˜ìµë¥ : {sum(total_returns)/len(total_returns):.2%}")
                            logger.info(f"  í‰ê·  ìƒ¤í”„ ë¹„ìœ¨: {sum(sharpe_ratios)/len(sharpe_ratios):.3f}")
                            logger.info(f"  í‰ê·  ìµœëŒ€ ë‚™í­: {sum(max_drawdowns)/len(max_drawdowns):.2%}")
                            logger.info(f"  í‰ê·  ìŠ¹ë¥ : {sum(win_rates)/len(win_rates):.2%}")
                            logger.info(f"  ì´ ê±°ë˜ ìˆ˜: {sum(total_trades):,}íšŒ")
                            logger.info(f"  ì²˜ë¦¬ ì¢…ëª© ìˆ˜: {len(results_data)}ê°œ")
        
        # ê²°ê³¼ ì €ì¥ (ê¸°ë³¸ ì €ì¥, --no-save-resultsë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥)
        if not getattr(args, 'no_save_results', False):
            output_dir = Path(args.output_dir)
            output_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # JSON ì €ì¥
            json_file = output_dir / f'backtest_results_{timestamp}.json'
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {json_file}")
        
        logger.info("\nâœ… ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ!")
        
    except Exception as e:
        import traceback
        logger.error(f"âŒ ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        logger.error(f"ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")

def run_streamlit():
    """Streamlit ì›¹ ì•± ì‹¤í–‰"""
    try:
        import streamlit.web.cli as stcli
        import sys
        
        # Streamlit ì•± íŒŒì¼ ê²½ë¡œ
        app_file = PROJECT_ROOT / 'streamlit_app' / 'app.py'
        
        if not app_file.exists():
            logger.error(f"Streamlit ì•± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {app_file}")
            logger.info("streamlit_app/app.pyë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return
        
        logger.info("Streamlit ì›¹ ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        logger.info("ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì„ ì—´ì–´ì£¼ì„¸ìš”.")
        
        # Streamlit ì‹¤í–‰
        sys.argv = ["streamlit", "run", str(app_file)]
        stcli.main()
        
    except Exception as e:
        logger.error(f"Streamlit ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        logger.info("Streamlitì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'pip install streamlit'ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

def run_optimization(args):
    """ë§¤ê°œë³€ìˆ˜ ìµœì í™” ì‹¤í–‰"""
    try:
        from src.strategies.macd_strategy import MACDStrategy
        from src.trading.parameter_optimizer import ParameterOptimizer
        import sqlite3
        
        logger.info("ğŸ”§ ë§¤ê°œë³€ìˆ˜ ìµœì í™” ì‹œì‘...")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ
        db_path = PROJECT_ROOT / 'data' / 'trading.db'
        
        if not db_path.exists():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
            return
        
        symbols = args.symbols if args.symbols else ['005930']  # ê¸°ë³¸: ì‚¼ì„±ì „ì
        data = {}
        
        with sqlite3.connect(db_path) as conn:
            for symbol in symbols:
                query = """
                SELECT date, open, high, low, close, volume 
                FROM stock_data 
                WHERE symbol = ? 
                ORDER BY date
                """
                df = pd.read_sql_query(query, conn, params=(symbol,))
                
                if not df.empty:
                    df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')
                    df.set_index('date', inplace=True)
                    data[symbol] = df
        
        if not data:
            logger.error("ìµœì í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë§¤ê°œë³€ìˆ˜ ë²”ìœ„ ì„¤ì •
        param_ranges = {
            'fast_period': [8, 10, 12, 14, 16],
            'slow_period': [21, 24, 26, 28, 30],
            'signal_period': [7, 8, 9, 10, 11]
        }
        
        # ìµœì í™” ì‹¤í–‰
        optimizer = ParameterOptimizer()
        results = optimizer.run_grid_search(
            strategy_class=MACDStrategy,
            data=data,
            param_ranges=param_ranges,
            metric='sharpe_ratio',
            max_combinations=50
        )
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n=== ìµœì í™” ê²°ê³¼ ===")
        logger.info(f"ìµœì  ë§¤ê°œë³€ìˆ˜: {results['best_parameters']}")
        logger.info(f"ìµœê³  ì„±ê³¼: {results['best_score']:.4f}")
        logger.info(f"í…ŒìŠ¤íŠ¸ ì¡°í•©: {results['total_combinations']}ê°œ")
        
    except Exception as e:
        logger.error(f"ìµœì í™” ì‹¤íŒ¨: {e}")

def run_check_data(args):
    """ì¢…í•© ë°ì´í„° ìƒíƒœ í™•ì¸ (check_data_status.py ê¸°ëŠ¥ í†µí•©)"""
    try:
        from scripts.data_update import StockDataUpdater
        
        updater = StockDataUpdater()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not Path(updater.db_path).exists():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            logger.info("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘í•˜ì„¸ìš”:")
            logger.info("python src/main.py update-data --top-kospi 50 --period 6m")
            return
        
        logger.info("ğŸ” ë°ì´í„° ìƒíƒœ ì¢…í•© ë¶„ì„ ì¤‘...")
        
        # ë¶„ì„ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
        days_back = getattr(args, 'days_back', 60)
        min_days = getattr(args, 'min_days', 30)
        top_limit = getattr(args, 'top_limit', 20)
        
        # ì¢…í•© ìƒíƒœ ë¶„ì„ ì‹¤í–‰
        comprehensive_status = updater.get_comprehensive_status(include_backtest_analysis=True)
        
        # ê¸°ë³¸ í˜„í™©
        basic = comprehensive_status.get('basic_summary', {})
        logger.info("\n" + "="*50)
        logger.info("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ í˜„í™©")
        logger.info("="*50)
        logger.info(f"ì´ ì¢…ëª© ìˆ˜: {basic.get('symbols_count', 0):,}ê°œ")
        logger.info(f"ë°ì´í„° ê¸°ê°„: {basic.get('date_range', ('N/A', 'N/A'))[0]} ~ {basic.get('date_range', ('N/A', 'N/A'))[1]}")
        logger.info(f"ì´ ë°ì´í„°: {basic.get('total_records', 0):,}ê±´")
        logger.info(f"DB íŒŒì¼: {basic.get('db_path', 'N/A')}")
        
        # ìµœê·¼ ì—…ë°ì´íŠ¸ ì •ë³´
        recent_updates = basic.get('recent_updates', [])
        if recent_updates:
            logger.info(f"\nğŸ“… ìµœê·¼ ì—…ë°ì´íŠ¸ ì¢…ëª© (ìƒìœ„ 5ê°œ):")
            for symbol, last_date in recent_updates:
                logger.info(f"  â€¢ {symbol}: {last_date}")
        
        # ë°±í…ŒìŠ¤íŒ… ë¶„ì„
        backtest = comprehensive_status.get('backtest_analysis', {})
        if backtest:
            logger.info(f"\n" + "="*50)
            logger.info("ğŸš€ ë°±í…ŒìŠ¤íŒ… ì í•©ì„± ë¶„ì„")
            logger.info("="*50)
            logger.info(f"ë¶„ì„ ê¸°ê°„: {backtest.get('analysis_period', 'N/A')}")
            logger.info(f"ìµœì†Œ ë°ì´í„° ìš”êµ¬: {backtest.get('min_data_days', 0)}ì¼ ì´ìƒ")
            logger.info(f"ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥ ì¢…ëª©: {backtest.get('valid_symbols_count', 0):,}ê°œ")
            logger.info(f"ì í•©ì„± ë¹„ìœ¨: {backtest.get('valid_percentage', 0)}% ({backtest.get('valid_symbols_count', 0)}/{basic.get('symbols_count', 0)})")
            
            # ìƒìœ„ ì¢…ëª© ìƒì„¸ í‘œì‹œ
            top_symbols = backtest.get('top_symbols', [])
            if top_symbols:
                logger.info(f"\nğŸ“ˆ ë°ì´í„°ê°€ ê°€ì¥ ì¶©ì‹¤í•œ ìƒìœ„ {len(top_symbols)}ê°œ ì¢…ëª©:")
                for i, symbol_info in enumerate(top_symbols, 1):
                    symbol = symbol_info['symbol']
                    days = symbol_info['days']
                    start_date = symbol_info['start_date']
                    end_date = symbol_info['end_date']
                    logger.info(f"  {i:2d}. {symbol}: {days:3d}ì¼ ({start_date} ~ {end_date})")
            
            # í…ŒìŠ¤íŠ¸ ì¶”ì²œ ì¢…ëª©
            test_symbols = backtest.get('test_symbols_string', '')
            if test_symbols:
                logger.info(f"\nğŸ¯ ë°±í…ŒìŠ¤íŒ… í…ŒìŠ¤íŠ¸ ì¶”ì²œ ì¢…ëª© (ìƒìœ„ 10ê°œ):")
                logger.info(f"   {test_symbols}")
                logger.info("\nğŸ’¡ ì‚¬ìš© ë°©ë²•:")
                logger.info(f"   python src/main.py backtest --symbols {' '.join(backtest.get('test_symbols', [])[:3])}")
                logger.info(f"   python src/main.py backtest --top-kospi 10 --strategy all")
        
        # API ì‚¬ìš© í˜„í™©
        api_status = comprehensive_status.get('api_status', {})
        if api_status and api_status.get('api_calls', 0) > 0:
            logger.info(f"\n" + "="*50)
            logger.info("ğŸ”Œ í˜„ì¬ ì„¸ì…˜ API ì‚¬ìš© í˜„í™©")
            logger.info("="*50)
            logger.info(f"API í˜¸ì¶œ: {api_status.get('api_calls', 0)}íšŒ")
            logger.info(f"ì„¸ì…˜ ì‹œê°„: {api_status.get('session_duration', 'N/A')}")
            logger.info(f"ë¶„ë‹¹ í˜¸ì¶œìœ¨: {api_status.get('calls_per_minute', 0):.1f}íšŒ/ë¶„")
            logger.info(f"ì°¸ê³ : {api_status.get('notes', 'N/A')}")
        
        # ì¶”ê°€ ê¶Œì¥ì‚¬í•­
        valid_count = backtest.get('valid_symbols_count', 0)
        total_count = basic.get('symbols_count', 0)
        
        logger.info(f"\n" + "="*50)
        logger.info("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
        logger.info("="*50)
        
        if valid_count == 0:
            logger.info("âš ï¸  ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥í•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            logger.info("   ë°ì´í„°ë¥¼ ë” ìˆ˜ì§‘í•˜ê±°ë‚˜ ê¸°ê°„ì„ ëŠ˜ë ¤ë³´ì„¸ìš”:")
            logger.info("   python src/main.py update-data --top-kospi 100 --period 1y")
        elif valid_count < 10:
            logger.info("âš ï¸  ë°±í…ŒìŠ¤íŒ… ê°€ëŠ¥í•œ ì¢…ëª©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            logger.info("   ë” ë§ì€ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
            logger.info("   python src/main.py update-data --top-kospi 50 --period 6m")
        elif valid_count < 50:
            logger.info("âœ… ì†Œê·œëª¨ ë°±í…ŒìŠ¤íŒ…ì— ì í•©í•©ë‹ˆë‹¤.")
            logger.info("   ì¶”ê°€ ì¢…ëª© ìˆ˜ì§‘ìœ¼ë¡œ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:")
            logger.info("   python src/main.py update-data --top-kospi 100 --period 1y")
        else:
            logger.info("ğŸ‰ ëŒ€ê·œëª¨ ë°±í…ŒìŠ¤íŒ…ì— ìµœì í™”ëœ ìƒíƒœì…ë‹ˆë‹¤!")
            logger.info("   ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ…ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”:")
            logger.info("   python src/main.py backtest --all-kospi --parallel --workers 8")
        
        # ë§ˆì§€ë§‰ ì‹¤í–‰ ëª…ë ¹ì–´ ì œì•ˆ
        if test_symbols:
            logger.info(f"\nğŸš€ ë°”ë¡œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ëª…ë ¹ì–´:")
            logger.info(f"   python src/main.py backtest --symbols {' '.join(backtest.get('test_symbols', [])[:5])}")
        
    except Exception as e:
        logger.error(f"ë°ì´í„° ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        logger.info("ê¸°ë³¸ ìƒíƒœ í™•ì¸ì„ ì‹œë„í•˜ì„¸ìš”:")
        logger.info("python src/main.py update-data --summary")

def load_backtest_results(file_path: str) -> dict:
    """ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def analyze_backtest_results_data(results: dict) -> pd.DataFrame:
    """ê²°ê³¼ ë¶„ì„ ë° DataFrame ë³€í™˜"""
    all_results = []
    
    for strategy, strategy_data in results.items():
        if 'results' not in strategy_data:
            continue
            
        for symbol, data in strategy_data['results'].items():
            if not data.get('success', False):
                continue
                
            # ê±°ë˜ê°€ ìˆëŠ” ê²½ìš°ë§Œ í¬í•¨ (0ê±°ë˜ëŠ” ì œì™¸)
            if data.get('total_trades', 0) == 0:
                continue
                
            result_row = {
                'strategy': strategy.upper(),
                'symbol': symbol,
                'total_return': data.get('total_return', 0) * 100,  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
                'sharpe_ratio': data.get('sharpe_ratio', 0),
                'max_drawdown': data.get('max_drawdown', 0) * 100,  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
                'win_rate': data.get('win_rate', 0) * 100,  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
                'total_trades': data.get('total_trades', 0),
                'data_points': data.get('data_points', 0)
            }
            all_results.append(result_row)
    
    if not all_results:
        logger.warning("ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    df = pd.DataFrame(all_results)
    return df

def create_sorted_analysis(df: pd.DataFrame, output_dir: str):
    """ì •ë ¬ëœ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. ìˆ˜ìµë¥  ê¸°ì¤€ ìƒìœ„ ì¢…ëª©
    logger.info("ğŸ“ˆ ìˆ˜ìµë¥  ê¸°ì¤€ ìƒìœ„ ì¢…ëª© ë¶„ì„...")
    top_returns = df.nlargest(50, 'total_return')
    returns_file = output_path / f"top_returns_{timestamp}.csv"
    top_returns.to_csv(returns_file, index=False, encoding='utf-8-sig')
    
    # 2. ìŠ¹ë¥  ê¸°ì¤€ ìƒìœ„ ì¢…ëª©
    logger.info("ğŸ¯ ìŠ¹ë¥  ê¸°ì¤€ ìƒìœ„ ì¢…ëª© ë¶„ì„...")
    top_winrates = df.nlargest(50, 'win_rate')
    winrates_file = output_path / f"top_winrates_{timestamp}.csv"
    top_winrates.to_csv(winrates_file, index=False, encoding='utf-8-sig')
    
    # 3. ìƒ¤í”„ ë¹„ìœ¨ ê¸°ì¤€ ìƒìœ„ ì¢…ëª©
    logger.info("âš–ï¸ ìƒ¤í”„ ë¹„ìœ¨ ê¸°ì¤€ ìƒìœ„ ì¢…ëª© ë¶„ì„...")
    top_sharpe = df.nlargest(50, 'sharpe_ratio')
    sharpe_file = output_path / f"top_sharpe_{timestamp}.csv"
    top_sharpe.to_csv(sharpe_file, index=False, encoding='utf-8-sig')
    
    # 4. ì¢…í•© ì ìˆ˜ ê¸°ì¤€ (ìˆ˜ìµë¥  + ìŠ¹ë¥  + ìƒ¤í”„ë¹„ìœ¨)
    logger.info("ğŸ† ì¢…í•© ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ ì¢…ëª© ë¶„ì„...")
    df['composite_score'] = (
        df['total_return'].fillna(0) * 0.4 +  # ìˆ˜ìµë¥  40%
        df['win_rate'].fillna(0) * 0.3 +      # ìŠ¹ë¥  30%
        df['sharpe_ratio'].fillna(0) * 30 * 0.3  # ìƒ¤í”„ë¹„ìœ¨ 30% (ìŠ¤ì¼€ì¼ ì¡°ì •)
    )
    top_composite = df.nlargest(50, 'composite_score')
    composite_file = output_path / f"top_composite_{timestamp}.csv"
    top_composite.to_csv(composite_file, index=False, encoding='utf-8-sig')
    
    # 5. ì „ëµë³„ í†µê³„
    logger.info("ğŸ“Š ì „ëµë³„ í†µê³„ ë¶„ì„...")
    strategy_stats = df.groupby('strategy').agg({
        'total_return': ['mean', 'median', 'std', 'max', 'min'],
        'win_rate': ['mean', 'median', 'std', 'max', 'min'],
        'sharpe_ratio': ['mean', 'median', 'std', 'max', 'min'],
        'total_trades': ['sum', 'mean'],
        'symbol': 'count'
    }).round(4)
    
    strategy_stats.columns = ['_'.join(col).strip() for col in strategy_stats.columns]
    strategy_file = output_path / f"strategy_stats_{timestamp}.csv"
    strategy_stats.to_csv(strategy_file, encoding='utf-8-sig')
    
    # 6. ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    logger.info("ğŸ“‹ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±...")
    create_detailed_report(df, top_returns, top_winrates, top_sharpe, top_composite, 
                          strategy_stats, output_path, timestamp)
    
    return {
        'top_returns': returns_file,
        'top_winrates': winrates_file, 
        'top_sharpe': sharpe_file,
        'top_composite': composite_file,
        'strategy_stats': strategy_file
    }

def create_detailed_report(df, top_returns, top_winrates, top_sharpe, top_composite, 
                          strategy_stats, output_path, timestamp):
    """ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    report_file = output_path / f"detailed_report_{timestamp}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ\n\n")
        f.write(f"**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**ë¶„ì„ ëŒ€ìƒ**: {len(df)}ê°œ ì¢…ëª©Ã—ì „ëµ ì¡°í•© (ê±°ë˜ ë°œìƒ ê±´ë§Œ)\n\n")
        
        # ì „ì²´ í†µê³„
        f.write("## ğŸ“Š ì „ì²´ í†µê³„ ìš”ì•½\n\n")
        f.write(f"- **í‰ê·  ìˆ˜ìµë¥ **: {df['total_return'].mean():.2f}%\n")
        f.write(f"- **í‰ê·  ìŠ¹ë¥ **: {df['win_rate'].mean():.2f}%\n") 
        f.write(f"- **í‰ê·  ìƒ¤í”„ ë¹„ìœ¨**: {df['sharpe_ratio'].mean():.3f}\n")
        f.write(f"- **ì´ ê±°ë˜ ìˆ˜**: {df['total_trades'].sum():,}íšŒ\n")
        f.write(f"- **ìˆ˜ìµë¥  > 0%**: {len(df[df['total_return'] > 0])}ê°œ ({len(df[df['total_return'] > 0])/len(df)*100:.1f}%)\n")
        f.write(f"- **ìŠ¹ë¥  > 50%**: {len(df[df['win_rate'] > 50])}ê°œ ({len(df[df['win_rate'] > 50])/len(df)*100:.1f}%)\n\n")
        
        # ìˆ˜ìµë¥  TOP 10
        f.write("## ğŸ¥‡ ìˆ˜ìµë¥  TOP 10\n\n")
        f.write("| ìˆœìœ„ | ì „ëµ | ì¢…ëª© | ìˆ˜ìµë¥  | ìŠ¹ë¥  | ìƒ¤í”„ë¹„ìœ¨ | ê±°ë˜ìˆ˜ |\n")
        f.write("|------|------|------|--------|------|----------|--------|\n")
        for i, row in top_returns.head(10).iterrows():
            f.write(f"| {len(top_returns) - list(top_returns.index).index(i)} | {row['strategy']} | {row['symbol']} | "
                   f"{row['total_return']:.2f}% | {row['win_rate']:.1f}% | {row['sharpe_ratio']:.3f} | {row['total_trades']} |\n")
        f.write("\n")
        
        # ìŠ¹ë¥  TOP 10  
        f.write("## ğŸ¯ ìŠ¹ë¥  TOP 10\n\n")
        f.write("| ìˆœìœ„ | ì „ëµ | ì¢…ëª© | ìŠ¹ë¥  | ìˆ˜ìµë¥  | ìƒ¤í”„ë¹„ìœ¨ | ê±°ë˜ìˆ˜ |\n")
        f.write("|------|------|------|------|--------|----------|--------|\n")
        for i, row in top_winrates.head(10).iterrows():
            f.write(f"| {len(top_winrates) - list(top_winrates.index).index(i)} | {row['strategy']} | {row['symbol']} | "
                   f"{row['win_rate']:.1f}% | {row['total_return']:.2f}% | {row['sharpe_ratio']:.3f} | {row['total_trades']} |\n")
        f.write("\n")
        
        # ìƒ¤í”„ ë¹„ìœ¨ TOP 10
        f.write("## âš–ï¸ ìƒ¤í”„ ë¹„ìœ¨ TOP 10\n\n")
        f.write("| ìˆœìœ„ | ì „ëµ | ì¢…ëª© | ìƒ¤í”„ë¹„ìœ¨ | ìˆ˜ìµë¥  | ìŠ¹ë¥  | ê±°ë˜ìˆ˜ |\n")
        f.write("|------|------|------|----------|--------|------|--------|\n")
        for i, row in top_sharpe.head(10).iterrows():
            f.write(f"| {len(top_sharpe) - list(top_sharpe.index).index(i)} | {row['strategy']} | {row['symbol']} | "
                   f"{row['sharpe_ratio']:.3f} | {row['total_return']:.2f}% | {row['win_rate']:.1f}% | {row['total_trades']} |\n")
        f.write("\n")
        
        # ì¢…í•© ì ìˆ˜ TOP 10
        f.write("## ğŸ† ì¢…í•© ì ìˆ˜ TOP 10\n\n")
        f.write("| ìˆœìœ„ | ì „ëµ | ì¢…ëª© | ì¢…í•©ì ìˆ˜ | ìˆ˜ìµë¥  | ìŠ¹ë¥  | ìƒ¤í”„ë¹„ìœ¨ | ê±°ë˜ìˆ˜ |\n")
        f.write("|------|------|------|----------|--------|------|----------|--------|\n")
        for i, row in top_composite.head(10).iterrows():
            f.write(f"| {len(top_composite) - list(top_composite.index).index(i)} | {row['strategy']} | {row['symbol']} | "
                   f"{row['composite_score']:.2f} | {row['total_return']:.2f}% | {row['win_rate']:.1f}% | "
                   f"{row['sharpe_ratio']:.3f} | {row['total_trades']} |\n")
        f.write("\n")
        
        # ì „ëµë³„ ì„±ê³¼
        f.write("## ğŸ“ˆ ì „ëµë³„ ì„±ê³¼ ë¹„êµ\n\n")
        f.write("| ì „ëµ | í‰ê·  ìˆ˜ìµë¥  | í‰ê·  ìŠ¹ë¥  | í‰ê·  ìƒ¤í”„ë¹„ìœ¨ | ì´ ê±°ë˜ìˆ˜ | ì¢…ëª©ìˆ˜ |\n")
        f.write("|------|-------------|-----------|---------------|----------|--------|\n")
        for strategy in strategy_stats.index:
            f.write(f"| {strategy} | {strategy_stats.loc[strategy, 'total_return_mean']:.2f}% | "
                   f"{strategy_stats.loc[strategy, 'win_rate_mean']:.1f}% | "
                   f"{strategy_stats.loc[strategy, 'sharpe_ratio_mean']:.3f} | "
                   f"{strategy_stats.loc[strategy, 'total_trades_sum']:.0f} | "
                   f"{strategy_stats.loc[strategy, 'symbol_count']:.0f} |\n")
        f.write("\n")
        
        # ì¶”ì²œ ì¢…ëª©
        f.write("## ğŸ’¡ íˆ¬ì ì¶”ì²œ ì¢…ëª©\n\n")
        recommended = top_composite.head(5)
        f.write("**ì¢…í•© ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ 5ê°œ ì¢…ëª© (ìˆ˜ìµë¥ , ìŠ¹ë¥ , ìƒ¤í”„ë¹„ìœ¨ ì¢…í•© ê³ ë ¤)**\n\n")
        for i, row in recommended.iterrows():
            f.write(f"### {row['symbol']} ({row['strategy']} ì „ëµ)\n")
            f.write(f"- **ìˆ˜ìµë¥ **: {row['total_return']:.2f}%\n")
            f.write(f"- **ìŠ¹ë¥ **: {row['win_rate']:.1f}%\n")
            f.write(f"- **ìƒ¤í”„ ë¹„ìœ¨**: {row['sharpe_ratio']:.3f}\n")
            f.write(f"- **ê±°ë˜ ìˆ˜**: {row['total_trades']}íšŒ\n")
            f.write(f"- **ì¢…í•© ì ìˆ˜**: {row['composite_score']:.2f}\n\n")

def run_analyze_results(args):
    """ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„ ì‹¤í–‰"""
    logger.info("ğŸ” ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„ ì‹œì‘...")
    
    # ìë™ ê²€ìƒ‰ ì˜µì…˜ ì²˜ë¦¬
    if args.auto_find or not Path(args.input).exists():
        backtest_dir = PROJECT_ROOT / 'backtest_results'
        if not backtest_dir.exists():
            logger.error(f"ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {backtest_dir}")
            return
            
        json_files = list(backtest_dir.glob('backtest_results_*.json'))
        if not json_files:
            logger.error("ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ íŒŒì¼(JSON)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            logger.info("ë¨¼ì € ë°±í…ŒìŠ¤íŒ…ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            logger.info("python src/main.py backtest --symbols 005930")
            return
            
        latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
        input_file = latest_file
        logger.info(f"ğŸ“ ìµœì‹  ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ íŒŒì¼ ì‚¬ìš©: {latest_file}")
    else:
        input_file = Path(args.input)
        if not input_file.exists():
            logger.error(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
            return
    
    # ê²°ê³¼ ë¡œë“œ
    results = load_backtest_results(str(input_file))
    if not results:
        logger.error("ê²°ê³¼ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¶„ì„
    df = analyze_backtest_results_data(results)
    if df.empty:
        logger.error("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"ğŸ“Š ì´ {len(df)}ê°œ ì¢…ëª©Ã—ì „ëµ ì¡°í•© ë¶„ì„ ì¤‘...")
    
    # ì •ë ¬ëœ ë¶„ì„ ê²°ê³¼ ìƒì„±
    output_files = create_sorted_analysis(df, args.output)
    
    logger.info("\n" + "="*60)
    logger.info("âœ… ë¶„ì„ ì™„ë£Œ!")
    logger.info("="*60)
    logger.info("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    for name, path in output_files.items():
        logger.info(f"   â€¢ {name}: {path}")
    
    # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
    logger.info("\nğŸ“Š ë¶„ì„ ìš”ì•½:")
    logger.info(f"   â€¢ ì „ì²´ ê²°ê³¼: {len(df)}ê°œ")
    logger.info(f"   â€¢ ìˆ˜ìµë¥  > 0%: {len(df[df['total_return'] > 0])}ê°œ ({len(df[df['total_return'] > 0])/len(df)*100:.1f}%)")
    logger.info(f"   â€¢ ìŠ¹ë¥  > 50%: {len(df[df['win_rate'] > 50])}ê°œ ({len(df[df['win_rate'] > 50])/len(df)*100:.1f}%)")
    logger.info(f"   â€¢ ìµœê³  ìˆ˜ìµë¥ : {df['total_return'].max():.2f}%")
    logger.info(f"   â€¢ ìµœê³  ìŠ¹ë¥ : {df['win_rate'].max():.1f}%")
    
    # TOP 5 ì¶”ì²œ ì¢…ëª© ì¶œë ¥
    if 'composite_score' in df.columns:
        top_5 = df.nlargest(5, 'composite_score')
        logger.info("\nğŸ’¡ TOP 5 ì¶”ì²œ ì¢…ëª© (ì¢…í•© ì ìˆ˜ ê¸°ì¤€):")
        for i, (_, row) in enumerate(top_5.iterrows(), 1):
            logger.info(f"   {i}. {row['symbol']} ({row['strategy']}) - "
                       f"ìˆ˜ìµë¥ : {row['total_return']:.2f}%, "
                       f"ìŠ¹ë¥ : {row['win_rate']:.1f}%, "
                       f"ìƒ¤í”„: {row['sharpe_ratio']:.3f}")

def show_available_commands():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ ëª©ë¡ í‘œì‹œ"""
    commands = {
        'check-deps': 'í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸',
        'check-data': 'ì¢…í•© ë°ì´í„° ìƒíƒœ í™•ì¸ (ë°±í…ŒìŠ¤íŒ… ì í•©ì„± ë¶„ì„)',
        'update-data': 'ì£¼ì‹ ë°ì´í„° ì—…ë°ì´íŠ¸',
        'backtest': 'ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰',
        'optimize': 'ë§¤ê°œë³€ìˆ˜ ìµœì í™”',
        'web': 'Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰',
        'analyze-results': 'ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±'
    }
    
    logger.info("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
    for cmd, desc in commands.items():
        logger.info(f"  â€¢ {cmd:<15} - {desc}")
    
    logger.info("\nğŸ’¡ ìì„¸í•œ ì‚¬ìš©ë²•:")
    logger.info("  python src/main.py <ëª…ë ¹ì–´> --help")
    logger.info("  python src/main.py --help              # ì „ì²´ ë„ì›€ë§")

def show_command_help(command: str):
    """íŠ¹ì • ëª…ë ¹ì–´ì˜ ìƒì„¸ ë„ì›€ë§ í‘œì‹œ"""
    command_examples = {
        'check-deps': [
            "python src/main.py check-deps"
        ],
        'check-data': [
            "python src/main.py check-data",
            "python src/main.py check-data --days-back 90 --min-days 45",
            "python src/main.py check-data --top-limit 30"
        ],
        'update-data': [
            "python src/main.py update-data",
            "python src/main.py update-data --symbols 005930 000660",
            "python src/main.py update-data --top-kospi 50",
            "python src/main.py update-data --all-kospi",
            "python src/main.py update-data --all-kospi --parallel --workers 8",
            "python src/main.py update-data --days 180",
            "python src/main.py update-data --period 6m",
            "python src/main.py update-data --start-date 2024-01-01",
            "python src/main.py update-data --yesterday-only",
            "python src/main.py update-data --all-kospi --yesterday-only",
            "python src/main.py update-data --summary",
            "python src/main.py update-data --api-status"
        ],
        'backtest': [
            "python src/main.py backtest",
            "python src/main.py backtest --symbols 005930 000660",
            "python src/main.py backtest --top-kospi 10",
            "python src/main.py backtest --all-kospi",
            "python src/main.py backtest --strategy rsi",
            "python src/main.py backtest --days 365",
            "python src/main.py backtest --start-date 2024-01-01 --end-date 2024-06-30",
            "python src/main.py backtest --parallel --workers 8",
            "python src/main.py backtest --optimized --chunk-size 50"
        ],
        'optimize': [
            "python src/main.py optimize",
            "python src/main.py optimize --symbols 005930"
        ],
        'web': [
            "python src/main.py web"
        ],
        'analyze-results': [
            "python src/main.py analyze-results",
            "python src/main.py analyze-results --auto-find",
            "python src/main.py analyze-results --input results.json",
            "python src/main.py analyze-results --output my_analysis"
        ]
    }
    
    if command in command_examples:
        logger.info(f"\nğŸ”§ '{command}' ëª…ë ¹ì–´ ì‚¬ìš© ì˜ˆì‹œ:")
        for example in command_examples[command]:
            logger.info(f"  {example}")
        logger.info(f"\nğŸ’¡ ìƒì„¸ ì˜µì…˜: python src/main.py {command} --help")
    else:
        logger.info(f"\nâ“ '{command}' ëª…ë ¹ì–´ì— ëŒ€í•œ ì˜ˆì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        show_available_commands()

def get_current_command_from_args() -> str:
    """í˜„ì¬ ì‹¤í–‰ëœ ëª…ë ¹ì–´ ì¶”ì¶œ"""
    import sys
    args = sys.argv[1:]  # ìŠ¤í¬ë¦½íŠ¸ ì´ë¦„ ì œì™¸
    
    valid_commands = ['check-deps', 'check-data', 'update-data', 'backtest', 'optimize', 'web', 'analyze-results']
    
    for arg in args:
        if arg in valid_commands:
            return arg
    
    return None

def suggest_similar_command(invalid_cmd: str, valid_commands: list) -> str:
    """ìœ ì‚¬í•œ ëª…ë ¹ì–´ ì œì•ˆ"""
    # ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ì„± ê²€ì‚¬
    suggestions = []
    for cmd in valid_commands:
        # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
        if invalid_cmd.lower() in cmd.lower() or cmd.lower() in invalid_cmd.lower():
            suggestions.append(cmd)
        # ì²« ê¸€ì ë§¤ì¹­
        elif cmd.lower().startswith(invalid_cmd.lower()[0]):
            suggestions.append(cmd)
    
    if suggestions:
        return f"í˜¹ì‹œ '{suggestions[0]}'ë¥¼ ì˜ë„í•˜ì…¨ë‚˜ìš”?"
    return ""

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    
    # í™˜ê²½ ì„¤ì •
    setup_environment()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(config)
    
    logger.info(f"=== {config['project']['name']} v{config['project']['version']} ===")
    
    # ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(
        description='TA-Lib ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python src/main.py check-deps           # íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
  
  # ë°ì´í„° ìƒíƒœ í™•ì¸ (í†µí•©ëœ check_data_status.py ê¸°ëŠ¥)
  python src/main.py check-data           # ì¢…í•© ë°ì´í„° ìƒíƒœ ë° ë°±í…ŒìŠ¤íŒ… ì í•©ì„± ë¶„ì„
  python src/main.py check-data --days-back 90 --min-days 45  # ì‚¬ìš©ì ì •ì˜ ë¶„ì„ ì¡°ê±´
  
  # ë°ì´í„° ì—…ë°ì´íŠ¸ (ê¸°ë³¸: 1ë…„ ë°ì´í„°)
  python src/main.py update-data          # ì½”ìŠ¤í”¼ ìƒìœ„ 30ì¢…ëª© 1ë…„ ë°ì´í„° ì—…ë°ì´íŠ¸
  python src/main.py update-data --top-kospi 50  # ì½”ìŠ¤í”¼ ìƒìœ„ 50ì¢…ëª© 1ë…„ ë°ì´í„°
  python src/main.py update-data --symbols 005930 000660  # íŠ¹ì • ì¢…ëª© 1ë…„ ë°ì´í„°
  
  # ë‚ ì§œ ë²”ìœ„ ì§€ì •
  python src/main.py update-data --days 180    # ìµœê·¼ 180ì¼ ë°ì´í„°
  python src/main.py update-data --period 6m   # ìµœê·¼ 6ê°œì›” ë°ì´í„°
  python src/main.py update-data --period 2y   # ìµœê·¼ 2ë…„ ë°ì´í„°
  python src/main.py update-data --start-date 2024-01-01 --end-date 2024-06-30  # íŠ¹ì • ê¸°ê°„
  python src/main.py update-data --start-date 20240101  # 2024ë…„ 1ì›” 1ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
  
  # ë¹ ë¥¸ ì—…ë°ì´íŠ¸ (Ultra-Fast)
  python src/main.py update-data --yesterday-only  # ì „ë‚  ë°ì´í„°ë§Œ (4-5ì´ˆ ì™„ë£Œ)
  python src/main.py update-data -y --top-kospi 30  # ì½”ìŠ¤í”¼ ìƒìœ„ 30ì¢…ëª© ì „ë‚  ë°ì´í„°
  
  # ìƒíƒœ í™•ì¸
  python src/main.py update-data --summary     # ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© í™•ì¸
  python src/main.py update-data --summary --backtest-analysis  # ë°±í…ŒìŠ¤íŒ… ë¶„ì„ í¬í•¨ ìƒì„¸ í˜„í™©
  python src/main.py update-data --api-status  # API ì‚¬ìš©ëŸ‰ í™•ì¸
  
  # ë°±í…ŒìŠ¤íŒ… (ê¸°ë³¸)
  python src/main.py backtest                  # ì‚¼ì„±ì „ì 180ì¼ ë°±í…ŒìŠ¤íŒ… (MACD ì „ëµ)
  python src/main.py backtest --symbols 005930 000660  # íŠ¹ì • ì¢…ëª© ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --strategy rsi   # RSI ì „ëµìœ¼ë¡œ ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --start-date 2024-01-01 --end-date 2024-06-30  # ê¸°ê°„ ì§€ì •
  
  # ëŒ€ê·œëª¨ ë°±í…ŒìŠ¤íŒ… (ë³‘ë ¬ ì²˜ë¦¬)
  python src/main.py backtest --top-kospi 10 --parallel  # ì½”ìŠ¤í”¼ ìƒìœ„ 10ì¢…ëª© ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --all-kospi --parallel --workers 8  # ì½”ìŠ¤í”¼ ì „ì²´ ë³‘ë ¬ ë°±í…ŒìŠ¤íŒ…
  python src/main.py backtest --strategy all --top-kospi 50 --parallel  # ëª¨ë“  ì „ëµ í…ŒìŠ¤íŠ¸
  
  # ê²°ê³¼ ì €ì¥ (ê¸°ë³¸ê°’, ë¹„í™œì„±í™”ëŠ” --no-save-results ì‚¬ìš©)
  python src/main.py backtest --all-kospi --parallel  # ê²°ê³¼ ìë™ ì €ì¥
  python src/main.py backtest --symbols 005930 --no-save-results  # ê²°ê³¼ ì €ì¥í•˜ì§€ ì•ŠìŒ
  
  # ë§¤ê°œë³€ìˆ˜ ìµœì í™” ë° ì›¹ ì¸í„°í˜ì´ìŠ¤
  python src/main.py optimize                 # ë§¤ê°œë³€ìˆ˜ ìµœì í™”
  python src/main.py web                      # ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
  
  # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„
  python src/main.py analyze-results          # ìµœì‹  ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ìë™ ë¶„ì„
  python src/main.py analyze-results --auto-find  # ìµœì‹  ê²°ê³¼ íŒŒì¼ ìë™ ê²€ìƒ‰ í›„ ë¶„ì„
  python src/main.py analyze-results --input backtest_results_20241207.json  # íŠ¹ì • íŒŒì¼ ë¶„ì„
  python src/main.py analyze-results --output my_analysis  # ì‚¬ìš©ì ì •ì˜ ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # íŒ¨í‚¤ì§€ í™•ì¸ ëª…ë ¹ì–´
    subparsers.add_parser('check-deps', help='í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸')
    
    # ë°ì´í„° ìƒíƒœ í™•ì¸ ëª…ë ¹ì–´ (í†µí•©ëœ check_data_status.py ê¸°ëŠ¥)
    check_parser = subparsers.add_parser('check-data', help='ì¢…í•© ë°ì´í„° ìƒíƒœ í™•ì¸ (ë°±í…ŒìŠ¤íŒ… ì í•©ì„± ë¶„ì„)')
    check_parser.add_argument('--days-back', type=int, default=60, help='ë¶„ì„ ê¸°ê°„ (í˜„ì¬ë¶€í„° Nì¼ ì „, ê¸°ë³¸: 60ì¼)')
    check_parser.add_argument('--min-days', type=int, default=30, help='ë°±í…ŒìŠ¤íŒ… ìµœì†Œ ë°ì´í„° ìš”êµ¬ ì¼ìˆ˜ (ê¸°ë³¸: 30ì¼)')
    check_parser.add_argument('--top-limit', type=int, default=20, help='ìƒìœ„ ì¢…ëª© í‘œì‹œ ê°œìˆ˜ (ê¸°ë³¸: 20ê°œ)')
    
    # ë°ì´í„° ì—…ë°ì´íŠ¸ ëª…ë ¹ì–´
    update_parser = subparsers.add_parser('update-data', help='ì£¼ì‹ ë°ì´í„° ì—…ë°ì´íŠ¸')
    update_parser.add_argument('--symbols', nargs='+', help='ì—…ë°ì´íŠ¸í•  ì¢…ëª© ì½”ë“œë“¤')
    update_parser.add_argument('--top-kospi', type=int, default=30, dest='top_kospi', help='ì½”ìŠ¤í”¼ ìƒìœ„ Nê°œ ì¢…ëª© (ê¸°ë³¸: 30)')
    update_parser.add_argument('--all-kospi', action='store_true', dest='all_kospi', help='ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª© ì—…ë°ì´íŠ¸ (~962ê°œ)')
    update_parser.add_argument('--force', action='store_true', help='ê°•ì œ ì—…ë°ì´íŠ¸')
    update_parser.add_argument('--summary', action='store_true', help='ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ë³´ê¸°')
    update_parser.add_argument('--backtest-analysis', action='store_true', dest='backtest_analysis', help='ë°±í…ŒìŠ¤íŒ… ì í•©ì„± ë¶„ì„ í¬í•¨ (--summaryì™€ í•¨ê»˜ ì‚¬ìš©)')
    update_parser.add_argument('--api-status', action='store_true', dest='api_status', help='API ì‚¬ìš©ëŸ‰ í˜„í™© ë³´ê¸°')
    update_parser.add_argument('--yesterday-only', '-y', action='store_true', dest='yesterday_only', help='ì „ë‚  ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸ (íš¨ìœ¨ì )')
    
    # ë‚ ì§œ ë²”ìœ„ ì˜µì…˜ ì¶”ê°€
    date_group = update_parser.add_argument_group('ë‚ ì§œ ë²”ìœ„ ì„¤ì •')
    date_group.add_argument('--days', type=int, help='í˜„ì¬ë¶€í„° Nì¼ ì „ê¹Œì§€ ë°ì´í„° ìˆ˜ì§‘ (ì˜ˆ: 180)')
    date_group.add_argument('--start-date', help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYYMMDD í˜•ì‹)')
    date_group.add_argument('--end-date', help='ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” YYYYMMDD í˜•ì‹, ê¸°ë³¸: ì˜¤ëŠ˜)')
    date_group.add_argument('--period', choices=['1w', '1m', '3m', '6m', '1y', '2y'], default='1y', 
                           help='ê¸°ë³¸ ìˆ˜ì§‘ ê¸°ê°„ (ê¸°ë³¸: 1y=1ë…„)')
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ ì¶”ê°€
    parallel_group = update_parser.add_argument_group('ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •')
    parallel_group.add_argument('--parallel', '-p', action='store_true', help='ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ (ë¹ ë¥¸ ì†ë„)')
    parallel_group.add_argument('--workers', type=int, default=5, help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 5)')
    
    # ë°±í…ŒìŠ¤íŒ… ëª…ë ¹ì–´
    backtest_parser = subparsers.add_parser('backtest', help='ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰')
    backtest_parser.add_argument('--symbols', nargs='+', help='ë°±í…ŒìŠ¤íŒ…í•  ì¢…ëª© ì½”ë“œë“¤')
    backtest_parser.add_argument('--top-kospi', type=int, help='ì½”ìŠ¤í”¼ ìƒìœ„ Nê°œ ì¢…ëª© ë°±í…ŒìŠ¤íŒ…')
    backtest_parser.add_argument('--all-kospi', action='store_true', help='ì½”ìŠ¤í”¼ ì „ì²´ ì¢…ëª© ë°±í…ŒìŠ¤íŒ… (962ê°œ)')
    backtest_parser.add_argument('--start-date', dest='start_date', help='ë°±í…ŒìŠ¤íŒ… ì‹œì‘ë‚ ì§œ (YYYY-MM-DD)')
    backtest_parser.add_argument('--end-date', dest='end_date', help='ë°±í…ŒìŠ¤íŒ… ì¢…ë£Œë‚ ì§œ (YYYY-MM-DD)')
    backtest_parser.add_argument('--days', type=int, default=180, help='ë°±í…ŒìŠ¤íŒ… ê¸°ê°„ (ì¼ìˆ˜, ê¸°ë³¸: 180ì¼)')
    backtest_parser.add_argument('--strategy', choices=['macd', 'rsi', 'bollinger', 'ma', 'all'], 
                                default='macd', help='ì‚¬ìš©í•  ì „ëµ (ê¸°ë³¸: macd, all: ëª¨ë“  ì „ëµ)')
    
    # ë°±í…ŒìŠ¤íŒ… ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜
    backtest_parallel_group = backtest_parser.add_argument_group('ì—”ì§„ ì„ íƒ ë° ì„±ëŠ¥ ì„¤ì •')
    backtest_parallel_group.add_argument('--parallel', '-p', action='store_true', help='ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ ê°•ì œ ì‚¬ìš© (ì¤‘ê·œëª¨ ìµœì )')
    backtest_parallel_group.add_argument('--optimized', '-o', action='store_true', help='ìµœì í™” ì—”ì§„ ê°•ì œ ì‚¬ìš© (ëŒ€ê·œëª¨ ìµœì , ìºì‹±)')
    backtest_parallel_group.add_argument('--workers', type=int, default=4, help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 4)')
    backtest_parallel_group.add_argument('--chunk-size', type=int, default=20, help='ì²­í¬ë‹¹ ì¢…ëª© ìˆ˜ (ê¸°ë³¸: 20)')
    
    # ìë™ ì—”ì§„ ì„ íƒ ì•ˆë‚´
    engine_help = backtest_parser.add_argument_group('ìë™ ì—”ì§„ ì„ íƒ (ì˜µì…˜ ë¯¸ì§€ì • ì‹œ)')
    engine_help.description = """
    ğŸ¤– ì¢…ëª© ìˆ˜ì— ë”°ë¥¸ ìë™ ì—”ì§„ ì„ íƒ:
    â€¢ 1-9ê°œ ì¢…ëª©: BacktestEngine (ìˆœì°¨ ì²˜ë¦¬, ë””ë²„ê¹… ìµœì )
    â€¢ 10-99ê°œ ì¢…ëª©: ParallelBacktestEngine (ë³‘ë ¬ ì²˜ë¦¬, ì„±ëŠ¥/ì•ˆì •ì„± ê· í˜•)  
    â€¢ 100ê°œ+ ì¢…ëª©: OptimizedBacktestEngine (ìºì‹±+ë³‘ë ¬+ë°°ì¹˜, ìµœê³  ì„±ëŠ¥)
    """
    
    # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì €ì¥ ì˜µì…˜ (ê¸°ë³¸ ì €ì¥)
    backtest_output_group = backtest_parser.add_argument_group('ê²°ê³¼ ì €ì¥ (ê¸°ë³¸: ì €ì¥í•¨)')
    backtest_output_group.add_argument('--no-save-results', action='store_true', help='ê²°ê³¼ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŒ (ê¸°ë³¸: ì €ì¥í•¨)')
    backtest_output_group.add_argument('--output-dir', default='backtest_results', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: backtest_results)')
    
    # ìµœì í™” ëª…ë ¹ì–´
    optimize_parser = subparsers.add_parser('optimize', help='ë§¤ê°œë³€ìˆ˜ ìµœì í™”')
    optimize_parser.add_argument('--symbols', nargs='+', help='ìµœì í™”í•  ì¢…ëª© ì½”ë“œë“¤')
    
    # ì›¹ ì¸í„°í˜ì´ìŠ¤ ëª…ë ¹ì–´
    subparsers.add_parser('web', help='Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰')
    
    # ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„ ëª…ë ¹ì–´
    analyze_parser = subparsers.add_parser('analyze-results', help='ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±')
    analyze_parser.add_argument('--input', '-i', 
                               default='backtest_results/backtest_results_latest.json',
                               help='ì…ë ¥ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (JSON í˜•ì‹)')
    analyze_parser.add_argument('--output', '-o', 
                               default='backtest_results/analysis',
                               help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: backtest_results/analysis)')
    analyze_parser.add_argument('--auto-find', action='store_true',
                               help='ìµœì‹  ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ íŒŒì¼ ìë™ ê²€ìƒ‰')
    
    # ì¸ì íŒŒì‹± ë° ì—ëŸ¬ ì²˜ë¦¬
    try:
        args = parser.parse_args()
    except SystemExit as e:
        # argparseì—ì„œ --helpë‚˜ ì˜ëª»ëœ ì¸ìë¡œ ì¸í•œ SystemExit ì²˜ë¦¬
        if e.code != 0:  # ì—ëŸ¬ë¡œ ì¸í•œ ì¢…ë£Œì¸ ê²½ìš°
            current_command = get_current_command_from_args()
            
            if current_command:
                # íŠ¹ì • ëª…ë ¹ì–´ì—ì„œ ì˜ëª»ëœ ì¸ì ì‚¬ìš©
                logger.error(f"\nâŒ '{current_command}' ëª…ë ¹ì–´ì—ì„œ ì˜ëª»ëœ ì¸ìë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
                show_command_help(current_command)
            else:
                # ì˜ëª»ëœ ëª…ë ¹ì–´ ë˜ëŠ” ì¼ë°˜ì ì¸ ì—ëŸ¬
                logger.error("\nâŒ ì˜ëª»ëœ ëª…ë ¹ì–´ ë˜ëŠ” ì¸ìì…ë‹ˆë‹¤.")
                show_available_commands()
        sys.exit(e.code)
    
    if not args.command:
        logger.info("ëª…ë ¹ì–´ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n")
        show_available_commands()
        logger.info("\nìì„¸í•œ ì‚¬ìš©ë²•ì€ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì„¸ìš”:")
        logger.info("python src/main.py --help")
        return
    
    # ëª…ë ¹ì–´ ì‹¤í–‰
    try:
        if args.command == 'check-deps':
            if check_dependencies():
                logger.info("\nì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                sys.exit(1)
                
        elif args.command == 'update-data':
            run_data_update(args)
            
        elif args.command == 'backtest':
            run_backtest(args)
            
        elif args.command == 'optimize':
            run_optimization(args)
            
        elif args.command == 'web':
            run_streamlit()
            
        elif args.command == 'check-data':
            run_check_data(args)
            
        elif args.command == 'analyze-results':
            run_analyze_results(args)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 